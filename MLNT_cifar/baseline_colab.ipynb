{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"baseline_colab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b768f845985d4aa9942389fbc33f2b2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ea94deaf86ca46fbb53943bbfb7397a4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0b8a2b9f6f224b3f94715ce8a32ab695","IPY_MODEL_58668cf853154bc09c152c26fcc381b7"]}},"ea94deaf86ca46fbb53943bbfb7397a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b8a2b9f6f224b3f94715ce8a32ab695":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5f96e12ed1dd48a89011264ee6316518","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":102502400,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102502400,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ce96b327901345fb9b4337882657cb75"}},"58668cf853154bc09c152c26fcc381b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bb0e64c6264c4d5aae4007d651c42e4d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [4:35:19&lt;00:00, 6.20kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d68acceddbb4af6b39d681dac55e960"}},"5f96e12ed1dd48a89011264ee6316518":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ce96b327901345fb9b4337882657cb75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb0e64c6264c4d5aae4007d651c42e4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9d68acceddbb4af6b39d681dac55e960":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"2AiEquVKc481","colab_type":"code","outputId":"119494e7-edfe-4c10-cb96-653769ae8e0c","executionInfo":{"status":"ok","timestamp":1587466307376,"user_tz":-120,"elapsed":16817,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install wandb"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/dd/ce719d36c4172b56c7579a79fcfd2f731c386b39f258bb186ef17b73fd7d/wandb-0.8.32-py2.py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 7.2MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Collecting watchdog>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n","\u001b[K     |████████████████████████████████| 102kB 9.6MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/1a/0df85d2bddbca33665d2148173d3281b290ac054b5f50163ea735740ac7b/GitPython-3.1.1-py3-none-any.whl (450kB)\n","\u001b[K     |████████████████████████████████| 460kB 36.1MB/s \n","\u001b[?25hCollecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/7e/19545324e83db4522b885808cd913c3b93ecc0c88b03e037b78c6a417fa8/sentry_sdk-0.14.3-py2.py3-none-any.whl (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 37.9MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.1)\n","Collecting gql==0.2.0\n","  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n","Collecting pathtools>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/52/ca35448b56c53a079d3ffe18b1978c6e424f6d4df02404877094c89f5bfb/gitdb-4.0.4-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.4.5.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n","Collecting graphql-core<2,>=0.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/27/b1/e379cfb7c07bbf8faee29c4a1a2469dbea525f047c2b454c4afdefa20a30/smmap-3.0.2-py2.py3-none-any.whl\n","Building wheels for collected packages: subprocess32, watchdog, gql, pathtools, graphql-core\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=f27f46b1e424a97592ef15afa3925feea8a36d3798bf52318185e313e5395ae9\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=a5ef2b2353715a1dad4d0b0483d5072b3c8981d6cf1f7e02ae6be42e088c3c3c\n","  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n","  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=df58368e3fe83bde6e68936233f1e6a3fe2ca36bd23fb8a786cd12ae25a89c76\n","  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=c9c08bd5ec913517258149440a62253424c42712cedf64bf8def04fb2a066e15\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=b76ee86d88d8cd34acb91982bf412b4d109a19cedc993b935b3d22280bf04814\n","  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n","Successfully built subprocess32 watchdog gql pathtools graphql-core\n","Installing collected packages: subprocess32, docker-pycreds, pathtools, watchdog, smmap, gitdb, GitPython, configparser, sentry-sdk, shortuuid, graphql-core, gql, wandb\n","Successfully installed GitPython-3.1.1 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.4 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.14.3 shortuuid-1.0.1 smmap-3.0.2 subprocess32-3.5.4 wandb-0.8.32 watchdog-0.10.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88ezc8iRdkqg","colab_type":"code","outputId":"712c740e-aab9-4fcf-b7be-44b3a88f3844","executionInfo":{"status":"ok","timestamp":1587466351609,"user_tz":-120,"elapsed":54845,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["!wandb login"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: dff003aa03e7d25df35a840b6f0660ae9675efb4\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8skRpihGdp1q","colab_type":"code","outputId":"83a6d28b-c172-42ca-870d-bb395fb54e83","executionInfo":{"status":"ok","timestamp":1587466353604,"user_tz":-120,"elapsed":56206,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["#GPU INFO\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tue Apr 21 10:52:31 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"csakjx4mdrs5","colab_type":"code","outputId":"a1a2340d-f7f5-4c8c-ab84-ea1ca9cba629","executionInfo":{"status":"ok","timestamp":1587466372222,"user_tz":-120,"elapsed":74298,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zoV2tev1jHbQ","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Colab_Notebooks/pfm/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5aYBRtwFjHXn","colab_type":"code","outputId":"33a0fec2-9ea6-4a46-feb0-78805419e407","executionInfo":{"status":"ok","timestamp":1587466392329,"user_tz":-120,"elapsed":88476,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["import models\n","import dataloader"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","noise file noisy_label_kv.txt generated with noise: 0.5\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://app.wandb.ai/xavierlopeze/Cifar_Experiment\" target=\"_blank\">https://app.wandb.ai/xavierlopeze/Cifar_Experiment</a><br/>\n","                Run page: <a href=\"https://app.wandb.ai/xavierlopeze/Cifar_Experiment/runs/7778fdz3\" target=\"_blank\">https://app.wandb.ai/xavierlopeze/Cifar_Experiment/runs/7778fdz3</a><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Xq88YZuGhRTA","colab_type":"code","colab":{}},"source":["# Internal files\n","import config\n","import dataloader\n","import models\n","\n","# Pytorch libraries\n","import torch\n","import torch.backends.cudnn as cudnn\n","\n","import os\n","import time\n","\n","import wandb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vreq6NGShRP8","colab_type":"code","colab":{}},"source":["def get_model():\n","\n","    # Get model from config\n","    if config.model == \"resnet18\":\n","        model = models.resnet18(pretrained=config.pretrained)\n","    elif config.model == \"resnet34\":\n","        model = models.resnet34(pretrained=config.pretrained)\n","    elif config.model == 'resnet50':\n","        model = models.resnet50(pretrained=config.pretrained)\n","    elif config.model == \"resnet101\":\n","        model = models.resnet101(pretrained=config.pretrained)\n","    elif config.model == \"resnet152\":\n","        model = models.resnet152(pretrained=config.pretrained)\n","    elif config.model == \"resnext50_32x4d\":\n","        model = models.resnet34(pretrained=config.pretrained)\n","    elif config.model == 'resnext101_32x8d':\n","        model = models.resnet50(pretrained=config.pretrained)\n","    elif config.model == \"wide_resnet50_2\":\n","        model = models.resnet101(pretrained=config.pretrained)\n","    elif config.model == \"wide_resnet101_2\":\n","        model = models.resnet152(pretrained=config.pretrained)\n","    else:\n","        raise ValueError('%s not supported'.format(config.model))\n","\n","    # Initialize fc layer\n","    (in_features, out_features) = model.fc.in_features, model.fc.out_features\n","    model.fc = torch.nn.Linear(in_features, out_features)\n","    return model\n","\n","\n","def scheduler(epoch: int):\n","    global lr\n","    lr = config.lr\n","    if epoch > config.start_epoch:\n","        lr = lr / 10.0\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","\n","def save_checkpoint(state, filename='checkpoint.pth.tar'):\n","    torch.save(state, filename)\n","    wandb.save(filename)\n","\n","def save_weights(epoch):\n","        print('| Saving Weights ...', end=\"\\r\")\n","        save_point = config.drive_dir + '/checkpoint/' + config.checkpoint + '_' + str(epoch) + '.pth.tar'\n","        save_checkpoint({'state_dict': net.state_dict(), }, save_point)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UG1lpyQugVk3","colab_type":"code","colab":{}},"source":["# Training\n","def train(epoch):\n","  net.train()\n","  train_loss = 0\n","  correct = 0\n","  total = 0\n","  scheduler(epoch)\n","\n","  # print(\"train before dataloader\")\n","  for step, (inputs, targets) in enumerate(train_loader):\n","      init_time = time.time()\n","      if use_cuda:  # GPU settings\n","          (inputs, targets) = inputs.cuda(), targets.cuda()\n","      optimizer.zero_grad()\n","      outputs = net(inputs)\n","      loss = criterion(outputs, targets)\n","      loss.backward()\n","      optimizer.step()\n","\n","      train_loss += loss.data.item()\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += targets.size(0)\n","      correct += predicted.eq(targets.data).cpu().sum()\n","\n","      # Grab training results\n","      # print(\"| Epoch: {}/{}, step: {}/{}, loss: {:.3f}, acc: {:.3f}, time: {:.3f}\".format(epoch,config.num_epochs,step + 1,len(train_loader.dataset),loss.data.item(),100. * correct / total,time.time() - init_time))\n","      # print(\"| Epoch: {}/{}, step: {}/{}, loss: {:.3f}, acc: {:.3f}, time: {:.3f}\".format(epoch,config.num_epochs,step + 1,len(train_loader.dataset),loss.data.item(),100. * correct / total,time.time() - init_time),end=\"\\r\")\n","      \n","      sys.stdout.write('\\r')\n","      sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%, time: %.3f'\n","              %(epoch, config.num_epochs, step+1, (len(train_loader.dataset)//config.batch_size)+1, loss.data.item(), 100.*correct/total,time.time() - init_time))\n","      sys.stdout.flush()\n","\n","def valid(epoch):\n","    global best_acc\n","    net.eval()\n","    # valid_loss = 0\n","    correct = 0\n","    total = 0\n","    for step, (inputs, targets) in enumerate(valid_loader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        with torch.no_grad():\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","            # valid_loss += loss.data.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets.data).cpu().sum()\n","\n","    # Grab validation results\n","    valid_acc = 100. * correct / total\n","    valid_results = (\"| Epoch: {}/{}, val_loss: {:.3f}, val_acc: {:.3f}, \"\"lr: {:.6f}\".format(epoch,config.num_epochs,loss.data.item(),valid_acc,lr))\n","    record.write(valid_results + '\\n')\n","    record.flush()\n","\n","    print(valid_results)\n","    wandb.log({'epoch': epoch, 'accy_val' : valid_acc })\n","    # Save checkpoint when best model\n","    if valid_acc > best_acc:\n","        best_acc = valid_acc\n","        print('| Saving Best Model ...', end=\"\\r\")\n","        save_point = config.drive_dir + '/checkpoint/' + str(config.checkpoint) + '.pth.tar'\n","        save_checkpoint({'state_dict': net.state_dict(), }, save_point)\n","\n","\n","\n","def test():\n","    test_net.eval()\n","    # test_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(valid_loader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        with torch.no_grad():\n","            outputs = test_net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","        # test_loss += loss.data.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","\n","    # Grab validation results\n","    test_acc = 100. * correct/total\n","    test_results = \"| test_loss: {:.3f}, test_acc: {:.3f}\".format(\n","        loss.data.item(), test_acc)\n","    record.write(test_results)\n","    record.flush()\n","\n","    print(test_results)\n","    wandb.log({'test_acc' : test_acc })\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7yJtSUNXm53L","colab_type":"code","colab":{}},"source":["config.drive_dir = '/content/drive/My Drive/Colab_Notebooks/pfm' #si es llença en local deixar en blanc \"\"\n","config.data_dir = '/content/drive/My Drive/Colab_Notebooks/pfm/data/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJ2JFsKWS2s6","colab_type":"code","outputId":"7c9a783b-06a9-4a65-e9aa-cd8a234b464c","executionInfo":{"status":"ok","timestamp":1587466432793,"user_tz":-120,"elapsed":15852,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":270,"referenced_widgets":["b768f845985d4aa9942389fbc33f2b2b","ea94deaf86ca46fbb53943bbfb7397a4","0b8a2b9f6f224b3f94715ce8a32ab695","58668cf853154bc09c152c26fcc381b7","5f96e12ed1dd48a89011264ee6316518","ce96b327901345fb9b4337882657cb75","bb0e64c6264c4d5aae4007d651c42e4d","9d68acceddbb4af6b39d681dac55e960"]}},"source":["record = open(config.drive_dir + '/checkpoint/' + config.checkpoint + '_test.txt', 'w')\n","record.write('noise_rate=%s\\n' % config.noise_rate)\n","record.flush()\n","\n","# Get the original_dataset\n","loader = dataloader.KeyDataLoader()\n","train_loader, valid_loader, test_loader = loader.run()\n","\n","# Hyper Parameter settings\n","torch.manual_seed(config.seed)\n","torch.cuda.manual_seed_all(config.seed)\n","use_cuda = torch.cuda.is_available()\n","\n","# Networks setup\n","print('\\nModel setup')\n","print('| Building network: {}'.format(config.model))\n","net = get_model()\n","test_net = get_model()\n","\n","if use_cuda:\n","    net.cuda()\n","    test_net.cuda()\n","    cudnn.benchmark = True\n","\n","# Instantiate a loss function.\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Instantiate an optimizer to train the model.\n","optimizer = torch.optim.SGD(\n","    net.parameters(), lr=config.lr, momentum=0.9, weight_decay=0.001)\n","\n","print('\\nTraining model')\n","print('| Training Epochs = ' + str(config.num_epochs))\n","print('| Initial Learning Rate = ' + str(config.lr))\n","print('| Optimizer = ' + str(config.optimizer_type))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n","  \"please use transforms.RandomResizedCrop instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Model setup\n","| Building network: resnet50\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b768f845985d4aa9942389fbc33f2b2b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=102502400), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","Training model\n","| Training Epochs = 100\n","| Initial Learning Rate = 0.0008\n","| Optimizer = SGD\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j1jjSHCQT8JQ","colab_type":"code","outputId":"f17dedfb-8245-4545-afb0-e1d46f1f2803","executionInfo":{"status":"ok","timestamp":1587455397664,"user_tz":-120,"elapsed":8968353,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["best_acc = 0\n","for epoch in range(1, 1 + config.num_epochs):\n","    train(epoch)\n","    valid(epoch)\n","    save_weights(epoch)\n","\n","\n","print('\\nTesting model')\n","\n","checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.checkpoint + '.pth.tar')\n","test_net.load_state_dict(checkpoint['state_dict'])\n","test()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["| Epoch [  1/100] Iter[1407/1407]\t\tLoss: 1.7837 Acc@1: 31.284%, time: 1.872| Epoch: 1/100, val_loss: 0.820, val_acc: 84.180, lr: 0.000800\n","| Epoch [  2/100] Iter[1407/1407]\t\tLoss: 2.0282 Acc@1: 39.020%, time: 0.074| Epoch: 2/100, val_loss: 0.842, val_acc: 88.380, lr: 0.000080\n","| Epoch [  3/100] Iter[1407/1407]\t\tLoss: 1.8871 Acc@1: 39.764%, time: 0.076| Epoch: 3/100, val_loss: 0.895, val_acc: 89.420, lr: 0.000080\n","| Epoch [  4/100] Iter[1407/1407]\t\tLoss: 2.0273 Acc@1: 40.249%, time: 0.078| Epoch: 4/100, val_loss: 0.750, val_acc: 89.720, lr: 0.000080\n","| Epoch [  5/100] Iter[1407/1407]\t\tLoss: 2.1324 Acc@1: 40.402%, time: 0.089| Epoch: 5/100, val_loss: 0.803, val_acc: 90.160, lr: 0.000080\n","| Epoch [  6/100] Iter[1407/1407]\t\tLoss: 2.2397 Acc@1: 40.622%, time: 0.125| Epoch: 6/100, val_loss: 0.743, val_acc: 90.080, lr: 0.000080\n","| Epoch [  7/100] Iter[1407/1407]\t\tLoss: 1.8580 Acc@1: 40.922%, time: 0.074| Epoch: 7/100, val_loss: 0.788, val_acc: 90.240, lr: 0.000080\n","| Epoch [  8/100] Iter[1407/1407]\t\tLoss: 1.7205 Acc@1: 41.324%, time: 0.075| Epoch: 8/100, val_loss: 0.645, val_acc: 90.280, lr: 0.000080\n","| Epoch [  9/100] Iter[1407/1407]\t\tLoss: 1.7339 Acc@1: 41.682%, time: 0.074| Epoch: 9/100, val_loss: 0.714, val_acc: 89.280, lr: 0.000080\n","| Epoch [ 10/100] Iter[1407/1407]\t\tLoss: 2.2455 Acc@1: 41.227%, time: 0.073| Epoch: 10/100, val_loss: 0.728, val_acc: 90.120, lr: 0.000080\n","| Epoch [ 11/100] Iter[1407/1407]\t\tLoss: 1.8385 Acc@1: 41.396%, time: 0.078| Epoch: 11/100, val_loss: 0.773, val_acc: 91.120, lr: 0.000080\n","| Epoch [ 12/100] Iter[1407/1407]\t\tLoss: 2.4558 Acc@1: 41.922%, time: 0.074| Epoch: 12/100, val_loss: 0.780, val_acc: 90.620, lr: 0.000080\n","| Epoch [ 13/100] Iter[1407/1407]\t\tLoss: 1.2800 Acc@1: 42.224%, time: 0.074| Epoch: 13/100, val_loss: 0.614, val_acc: 90.980, lr: 0.000080\n","| Epoch [ 14/100] Iter[1407/1407]\t\tLoss: 2.2655 Acc@1: 42.122%, time: 0.073| Epoch: 14/100, val_loss: 0.706, val_acc: 90.700, lr: 0.000080\n","| Epoch [ 15/100] Iter[1407/1407]\t\tLoss: 2.5556 Acc@1: 42.273%, time: 0.074| Epoch: 15/100, val_loss: 0.798, val_acc: 91.300, lr: 0.000080\n","| Epoch [ 16/100] Iter[1407/1407]\t\tLoss: 2.2106 Acc@1: 42.487%, time: 0.073| Epoch: 16/100, val_loss: 0.801, val_acc: 90.580, lr: 0.000080\n","| Epoch [ 17/100] Iter[1407/1407]\t\tLoss: 2.0455 Acc@1: 42.509%, time: 0.074| Epoch: 17/100, val_loss: 0.734, val_acc: 91.480, lr: 0.000080\n","| Epoch [ 18/100] Iter[1407/1407]\t\tLoss: 1.6177 Acc@1: 42.540%, time: 0.073| Epoch: 18/100, val_loss: 0.704, val_acc: 90.680, lr: 0.000080\n","| Epoch [ 19/100] Iter[1407/1407]\t\tLoss: 2.1660 Acc@1: 42.853%, time: 0.075| Epoch: 19/100, val_loss: 0.624, val_acc: 91.440, lr: 0.000080\n","| Epoch [ 20/100] Iter[1407/1407]\t\tLoss: 1.9224 Acc@1: 42.969%, time: 0.074| Epoch: 20/100, val_loss: 0.555, val_acc: 90.180, lr: 0.000080\n","| Epoch [ 21/100] Iter[1407/1407]\t\tLoss: 1.4658 Acc@1: 43.060%, time: 0.077| Epoch: 21/100, val_loss: 0.668, val_acc: 91.220, lr: 0.000080\n","| Epoch [ 22/100] Iter[1407/1407]\t\tLoss: 2.3122 Acc@1: 42.998%, time: 0.073| Epoch: 22/100, val_loss: 0.741, val_acc: 90.280, lr: 0.000080\n","| Epoch [ 23/100] Iter[1407/1407]\t\tLoss: 1.9470 Acc@1: 43.156%, time: 0.077| Epoch: 23/100, val_loss: 0.702, val_acc: 90.360, lr: 0.000080\n","| Epoch [ 24/100] Iter[1407/1407]\t\tLoss: 2.0145 Acc@1: 43.280%, time: 0.074| Epoch: 24/100, val_loss: 0.580, val_acc: 90.420, lr: 0.000080\n","| Epoch [ 25/100] Iter[1407/1407]\t\tLoss: 1.4704 Acc@1: 43.307%, time: 0.073| Epoch: 25/100, val_loss: 0.697, val_acc: 90.040, lr: 0.000080\n","| Epoch [ 26/100] Iter[1407/1407]\t\tLoss: 2.3417 Acc@1: 43.564%, time: 0.074| Epoch: 26/100, val_loss: 0.452, val_acc: 89.740, lr: 0.000080\n","| Epoch [ 27/100] Iter[1407/1407]\t\tLoss: 1.5762 Acc@1: 43.740%, time: 0.073| Epoch: 27/100, val_loss: 0.555, val_acc: 90.460, lr: 0.000080\n","| Epoch [ 28/100] Iter[1407/1407]\t\tLoss: 2.4344 Acc@1: 43.660%, time: 0.073| Epoch: 28/100, val_loss: 0.661, val_acc: 89.660, lr: 0.000080\n","| Epoch [ 29/100] Iter[1407/1407]\t\tLoss: 2.1922 Acc@1: 43.782%, time: 0.074| Epoch: 29/100, val_loss: 0.627, val_acc: 90.680, lr: 0.000080\n","| Epoch [ 30/100] Iter[1407/1407]\t\tLoss: 2.0489 Acc@1: 44.089%, time: 0.073| Epoch: 30/100, val_loss: 0.550, val_acc: 89.740, lr: 0.000080\n","| Epoch [ 31/100] Iter[1407/1407]\t\tLoss: 2.1935 Acc@1: 44.247%, time: 0.074| Epoch: 31/100, val_loss: 0.627, val_acc: 89.900, lr: 0.000080\n","| Epoch [ 32/100] Iter[1407/1407]\t\tLoss: 2.1750 Acc@1: 44.318%, time: 0.073| Epoch: 32/100, val_loss: 0.490, val_acc: 89.500, lr: 0.000080\n","| Epoch [ 33/100] Iter[1407/1407]\t\tLoss: 2.5874 Acc@1: 44.467%, time: 0.074| Epoch: 33/100, val_loss: 0.635, val_acc: 88.680, lr: 0.000080\n","| Epoch [ 34/100] Iter[1407/1407]\t\tLoss: 1.9607 Acc@1: 44.344%, time: 0.078| Epoch: 34/100, val_loss: 0.544, val_acc: 88.860, lr: 0.000080\n","| Epoch [ 35/100] Iter[1407/1407]\t\tLoss: 1.5388 Acc@1: 44.778%, time: 0.075| Epoch: 35/100, val_loss: 0.555, val_acc: 88.980, lr: 0.000080\n","| Epoch [ 36/100] Iter[1407/1407]\t\tLoss: 1.6597 Acc@1: 44.736%, time: 0.077| Epoch: 36/100, val_loss: 0.592, val_acc: 87.760, lr: 0.000080\n","| Epoch [ 37/100] Iter[1407/1407]\t\tLoss: 1.2914 Acc@1: 44.791%, time: 0.075| Epoch: 37/100, val_loss: 0.582, val_acc: 87.940, lr: 0.000080\n","| Epoch [ 38/100] Iter[1407/1407]\t\tLoss: 1.7634 Acc@1: 44.776%, time: 0.074| Epoch: 38/100, val_loss: 0.467, val_acc: 86.060, lr: 0.000080\n","| Epoch [ 39/100] Iter[1407/1407]\t\tLoss: 2.1680 Acc@1: 45.222%, time: 0.073| Epoch: 39/100, val_loss: 0.525, val_acc: 86.480, lr: 0.000080\n","| Epoch [ 40/100] Iter[1407/1407]\t\tLoss: 1.7518 Acc@1: 45.318%, time: 0.075| Epoch: 40/100, val_loss: 0.444, val_acc: 86.540, lr: 0.000080\n","| Epoch [ 41/100] Iter[1407/1407]\t\tLoss: 1.8247 Acc@1: 45.278%, time: 0.075| Epoch: 41/100, val_loss: 0.531, val_acc: 84.220, lr: 0.000080\n","| Epoch [ 42/100] Iter[1407/1407]\t\tLoss: 2.0364 Acc@1: 45.687%, time: 0.074| Epoch: 42/100, val_loss: 0.476, val_acc: 86.320, lr: 0.000080\n","| Epoch [ 43/100] Iter[1407/1407]\t\tLoss: 1.9053 Acc@1: 45.562%, time: 0.074| Epoch: 43/100, val_loss: 0.389, val_acc: 86.440, lr: 0.000080\n","| Epoch [ 44/100] Iter[1407/1407]\t\tLoss: 1.8537 Acc@1: 45.907%, time: 0.075| Epoch: 44/100, val_loss: 0.427, val_acc: 83.500, lr: 0.000080\n","| Epoch [ 45/100] Iter[1407/1407]\t\tLoss: 1.7939 Acc@1: 46.138%, time: 0.074| Epoch: 45/100, val_loss: 0.600, val_acc: 84.880, lr: 0.000080\n","| Epoch [ 46/100] Iter[1407/1407]\t\tLoss: 2.3088 Acc@1: 46.180%, time: 0.073| Epoch: 46/100, val_loss: 0.514, val_acc: 83.600, lr: 0.000080\n","| Epoch [ 47/100] Iter[1407/1407]\t\tLoss: 1.5634 Acc@1: 46.580%, time: 0.074| Epoch: 47/100, val_loss: 0.507, val_acc: 82.340, lr: 0.000080\n","| Epoch [ 48/100] Iter[1407/1407]\t\tLoss: 1.1935 Acc@1: 46.853%, time: 0.079| Epoch: 48/100, val_loss: 0.542, val_acc: 80.520, lr: 0.000080\n","| Epoch [ 49/100] Iter[1407/1407]\t\tLoss: 1.9807 Acc@1: 47.053%, time: 0.073| Epoch: 49/100, val_loss: 0.621, val_acc: 78.340, lr: 0.000080\n","| Epoch [ 50/100] Iter[1407/1407]\t\tLoss: 2.1846 Acc@1: 47.589%, time: 0.073| Epoch: 50/100, val_loss: 0.722, val_acc: 79.080, lr: 0.000080\n","| Epoch [ 51/100] Iter[1407/1407]\t\tLoss: 1.7563 Acc@1: 47.384%, time: 0.073| Epoch: 51/100, val_loss: 0.467, val_acc: 77.020, lr: 0.000080\n","| Epoch [ 52/100] Iter[1407/1407]\t\tLoss: 1.3480 Acc@1: 48.104%, time: 0.074| Epoch: 52/100, val_loss: 0.632, val_acc: 77.420, lr: 0.000080\n","| Epoch [ 53/100] Iter[813/1407]\t\tLoss: 1.6201 Acc@1: 49.028%, time: 0.227Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oyyFzY5r6yTV","colab_type":"text"},"source":[""]}]}