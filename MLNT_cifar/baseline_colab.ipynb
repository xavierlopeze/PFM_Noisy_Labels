{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11415,
     "status": "ok",
     "timestamp": 1588099119092,
     "user": {
      "displayName": "Xavier López",
      "photoUrl": "",
      "userId": "17793741074420892205"
     },
     "user_tz": -120
    },
    "id": "2AiEquVKc481",
    "outputId": "2af092f4-2e4b-44df-96bd-e16a295f58c1",
    "scrolled": true
   },
   "source": [
    "# Baseline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch in colab\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66033,
     "status": "ok",
     "timestamp": 1588099173737,
     "user": {
      "displayName": "Xavier López",
      "photoUrl": "",
      "userId": "17793741074420892205"
     },
     "user_tz": -120
    },
    "id": "88ezc8iRdkqg",
    "outputId": "d32c5940-3ab1-4aff-c80a-f0f4781f448f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: dff003aa03e7d25df35a840b6f0660ae9675efb4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86637,
     "status": "ok",
     "timestamp": 1588099194363,
     "user": {
      "displayName": "Xavier López",
      "photoUrl": "",
      "userId": "17793741074420892205"
     },
     "user_tz": -120
    },
    "id": "csakjx4mdrs5",
    "outputId": "ef30ed09-538e-4f4c-a1da-007292b757e1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-91874b305a32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#launch in colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 30 22:55:24 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 425.45       Driver Version: 425.45       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 105... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P8    N/A /  N/A |     75MiB /  4096MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     10948    C+G   ...ng4wbp0\\app\\DellMobileConnectClient.exe N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#GPU INFO\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoV2tev1jHbQ"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##launch in colab\n",
    "# sys.path.append('/content/drive/My Drive/Colab_Notebooks/pfm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xq88YZuGhRTA"
   },
   "outputs": [],
   "source": [
    "# Internal files\n",
    "import config\n",
    "import dataloader\n",
    "import models\n",
    "\n",
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vreq6NGShRP8"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "\n",
    "    # Get model from config\n",
    "    if config.model == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=config.pretrained)\n",
    "    elif config.model == \"resnet34\":\n",
    "        model = models.resnet34(pretrained=config.pretrained)\n",
    "    elif config.model == 'resnet50':\n",
    "        model = models.resnet50(pretrained=config.pretrained)\n",
    "    elif config.model == \"resnet101\":\n",
    "        model = models.resnet101(pretrained=config.pretrained)\n",
    "    elif config.model == \"resnet152\":\n",
    "        model = models.resnet152(pretrained=config.pretrained)\n",
    "    elif config.model == \"resnext50_32x4d\":\n",
    "        model = models.resnet34(pretrained=config.pretrained)\n",
    "    elif config.model == 'resnext101_32x8d':\n",
    "        model = models.resnet50(pretrained=config.pretrained)\n",
    "    elif config.model == \"wide_resnet50_2\":\n",
    "        model = models.resnet101(pretrained=config.pretrained)\n",
    "    elif config.model == \"wide_resnet101_2\":\n",
    "        model = models.resnet152(pretrained=config.pretrained)\n",
    "    else:\n",
    "        raise ValueError('%s not supported'.format(config.model))\n",
    "\n",
    "    # Initialize fc layer\n",
    "    (in_features, out_features) = model.fc.in_features, model.fc.out_features\n",
    "    model.fc = torch.nn.Linear(in_features, out_features)\n",
    "    return model\n",
    "\n",
    "\n",
    "def scheduler(epoch: int):\n",
    "    global lr\n",
    "    lr = config.lr\n",
    "    if epoch > config.start_epoch:\n",
    "        lr = lr / 10.0\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if config.use_wandb == True:\n",
    "        wandb.save(filename)\n",
    "\n",
    "def save_weights(epoch):\n",
    "        print('| Saving Weights ...', end=\"\\r\")\n",
    "        save_point = config.drive_dir + '/checkpoint/' + config.checkpoint + '_' + str(epoch) + '.pth.tar'\n",
    "        save_checkpoint({'state_dict': net.state_dict(), }, save_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UG1lpyQugVk3"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "  net.train()\n",
    "  train_loss = 0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  scheduler(epoch)\n",
    "\n",
    "  # print(\"train before dataloader\")\n",
    "  for step, (inputs, targets) in enumerate(train_loader):\n",
    "      init_time = time.time()\n",
    "      if use_cuda:  # GPU settings\n",
    "          (inputs, targets) = inputs.cuda(), targets.cuda()\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      train_loss += loss.data.item()\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += targets.size(0)\n",
    "      correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "      # Grab training results\n",
    "      # print(\"| Epoch: {}/{}, step: {}/{}, loss: {:.3f}, acc: {:.3f}, time: {:.3f}\".format(epoch,config.num_epochs,step + 1,len(train_loader.dataset),loss.data.item(),100. * correct / total,time.time() - init_time))\n",
    "      # print(\"| Epoch: {}/{}, step: {}/{}, loss: {:.3f}, acc: {:.3f}, time: {:.3f}\".format(epoch,config.num_epochs,step + 1,len(train_loader.dataset),loss.data.item(),100. * correct / total,time.time() - init_time),end=\"\\r\")\n",
    "      \n",
    "      sys.stdout.write('\\r')\n",
    "      sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%, time: %.3f'\n",
    "              %(epoch, config.num_epochs, step+1, (len(train_loader.dataset)//config.batch_size)+1, loss.data.item(), 100.*correct/total,time.time() - init_time))\n",
    "      sys.stdout.flush()\n",
    "\n",
    "def valid(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    # valid_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for step, (inputs, targets) in enumerate(valid_loader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            # valid_loss += loss.data.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    # Grab validation results\n",
    "    valid_acc = 100. * correct / total\n",
    "    valid_results = (\"| Epoch: {}/{}, val_loss: {:.3f}, val_acc: {:.3f}, \"\"lr: {:.6f}\".format(epoch,config.num_epochs,loss.data.item(),valid_acc,lr))\n",
    "    record.write(valid_results + '\\n')\n",
    "    record.flush()\n",
    "\n",
    "    if config.use_wandb == True:\n",
    "        wandb.log({'epoch': epoch, 'accy_val' : valid_acc })\n",
    "        \n",
    "    # Save checkpoint when best model\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        print('| Saving Best Model ...', end=\"\\r\")\n",
    "        save_point = config.drive_dir + '/checkpoint/' + str(config.checkpoint) + '.pth.tar'\n",
    "        save_checkpoint({'state_dict': net.state_dict(), }, save_point)\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    test_net.eval()\n",
    "    # test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = test_net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "        # test_loss += loss.data.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    # Grab validation results\n",
    "    test_acc = 100. * correct/total\n",
    "    test_results = \"| test_loss: {:.3f}, test_acc: {:.3f}\".format(\n",
    "        loss.data.item(), test_acc)\n",
    "    record.write(test_results)\n",
    "    record.flush()\n",
    "\n",
    "    print(test_results)\n",
    "    wandb.log({'test_acc' : test_acc })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yJtSUNXm53L"
   },
   "outputs": [],
   "source": [
    "config.drive_dir = ''#'/content/drive/My Drive/Colab_Notebooks/pfm' #si es llença en local deixar en blanc \"\"\n",
    "config.data_dir = './data/'#'/content/drive/My Drive/Colab_Notebooks/pfm/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280,
     "referenced_widgets": [
      "3271b94bca1f4e5cb9c52119fa0bf3c5",
      "8be9ca007a2e4dafa1eebbfdb43a6aca",
      "e1accdd5a2eb47dea84e5eb84b6da723",
      "3bde9f328709474cad96f8e0ab143cec",
      "2bb2a28a69994812a4f3b0c44c929952",
      "ce8de694a4d14ac599683e6a5425f92f",
      "3644e0b4152a4daf86228ca51f50afc8",
      "e028b7fe53434234972a266b9d093484"
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16672,
     "status": "ok",
     "timestamp": 1588099247566,
     "user": {
      "displayName": "Xavier López",
      "photoUrl": "",
      "userId": "17793741074420892205"
     },
     "user_tz": -120
    },
    "id": "hJ2JFsKWS2s6",
    "outputId": "269f9ee2-eb51-49fc-e47d-7d30213e0dbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model setup\n",
      "| Building network: resnet34\n",
      "\n",
      "Training model\n",
      "| Training Epochs = 5\n",
      "| Initial Learning Rate = 0.0008\n",
      "| Optimizer = SGD\n"
     ]
    }
   ],
   "source": [
    "record = open(config.drive_dir + './checkpoint/' + config.checkpoint + '_test.txt', 'w')\n",
    "record.write('noise_rate=%s\\n' % config.noise_rate)\n",
    "record.flush()\n",
    "\n",
    "# Get the original_dataset\n",
    "loader = dataloader.KeyDataLoader()\n",
    "train_loader, valid_loader, test_loader = loader.run()\n",
    "\n",
    "# Hyper Parameter settings\n",
    "torch.manual_seed(config.seed)\n",
    "torch.cuda.manual_seed_all(config.seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Networks setup\n",
    "print('\\nModel setup')\n",
    "print('| Building network: {}'.format(config.model))\n",
    "net = get_model()\n",
    "test_net = get_model()\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    test_net.cuda()\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Instantiate a loss function.\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = torch.optim.SGD(\n",
    "    net.parameters(), lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n",
    "\n",
    "print('\\nTraining model')\n",
    "print('| Training Epochs = ' + str(config.num_epochs))\n",
    "print('| Initial Learning Rate = ' + str(config.lr))\n",
    "print('| Optimizer = ' + str(config.optimizer_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_point = config.drive_dir + './checkpoint/' + str(config.checkpoint) + '.pth.tar'\n",
    "save_checkpoint({'state_dict': net.state_dict(), }, save_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 750,
     "status": "error",
     "timestamp": 1588099976428,
     "user": {
      "displayName": "Xavier López",
      "photoUrl": "",
      "userId": "17793741074420892205"
     },
     "user_tz": -120
    },
    "id": "j1jjSHCQT8JQ",
    "outputId": "1dd45a7b-2bf1-496a-cdf9-d33f4fdf877b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [  1/  5] Iter[ 25/9001]\t\tLoss: 2.8796 Acc@1: 9.600%, time: 0.1792"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-58021da09e0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mvalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-7de456f78875>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     12\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# GPU settings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m           \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m       \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PFM\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for epoch in range(1, 1 + config.num_epochs):\n",
    "    train(epoch)\n",
    "    valid(epoch)\n",
    "    save_weights(epoch)\n",
    "\n",
    "print('\\nTesting model')\n",
    "\n",
    "checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.checkpoint + '.pth.tar')\n",
    "test_net.load_state_dict(checkpoint['state_dict'])\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1588099607426,
     "user": {
      "displayName": "Xavier López",
      "photoUrl": "",
      "userId": "17793741074420892205"
     },
     "user_tz": -120
    },
    "id": "KqappFXHHJvk",
    "outputId": "86e04279-2813-43cf-b683-af447e7ad86c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJjklEQVR4nG2WWY8cZxWGv7X26qrurqp2d0/P5pmxJ47jhQQQ4QIJsUnhEokL/gD5OwjxMxBCghAhnNg4ARR5iZ3M4mVmenp6qe7qqq59/7hwEjlS3rtzLt6j9+Kc50DwmiCAEMD6VcFRUZYMQ9cbcttoGYYOWM1RwvG847ijySwrK0xonuZpnCRRFAdhGiVlUYNvC75eIIgRQIQjWlsXNRlx2Fhryoog8VzXaKmCqChKWpQVA8cvTuy5kxUlrBCHCKvqIs2yJJlPFys3KIryG0/yrWkIay1j/9qVN69fNU09SaMEpIACgSN1kQs89ZPQ8QJF06ksklhMoijwVzzEDUVhuLZ6ZrfXPTkeTi6mWZ4xxl4lgBACBgAEYGN3d+/Gja31tb2NvqlJCk8QTyoET0fDZ6fPFV0dTSbD0VRRG7LayIr6fDQiDHAIsKIiCMmixFPBnfnecjUcDgM/AAAQCDADNabIMNs7V7f0Jp8kK3uOYSnDlmRwnCSopWUsfH8W+vMwToscJzFgQBLEa9tbaZa6ngdrpjc0AlEUxUJTFFhm1ZbgCqvlijDAEEa8LCitRlGlcbDMAeXqcm/rhiijIg8KAte6a15RXjx+JCkSgy2B4zmMEQNGp5nEGcfzo7NhGAYtXW82taKqKI95nlqmMRlNCKawaTYVXUEETqfjKJINzejsbFdFmka1ogltw1ilmSJwZkMMY6fRUgmhAuXiIJwtZzwReIEYZjNP06LIVqulrMiyzAm0KfNSS1eJ2JAERWi29UZLuzg/jXzPVDVvuSB1uLVhWuZas9lyR3PEiv3LG1kVLNM8z4usyESOyKKUxBmEaDDo1VUVByHHIYDqsigEgWqaLFBMalBlRVbWJS/yaxsDbzZ/8eJFlaZou7+/s9brDxDmZDHgwyDI08GlTo8KzsKp65qnNIniEucIY0URAQOB50LMJFlcOsuyzIMIi5yA8rgokmoxWzozRxLVOGcT202SMo2KlmaaZi9chbHjmrJq6maZMhnxg07faBkQEy+OAQII1vPFzHHtltU0Ooba0CGmQZpUBAZlQsqs9BZLbwXDKAAVY0nR4ASWxiKprZa0mIyGz5/5ni+ojY2NdQbR3PG3ty+fj8fzysnE3PEdyMEvDo5UVd27spfnVZbEjKFW21y6nuu5BNQ1AAAUTKC8wnGIUtM0cVVwmB1+8ci1Z4hIgqxQUSrzytJMVehYaueNd6/Livz48eO/3vnbyWRIsYAYPT8dR1FstNqqqlNKMaJFUUMEICKo2790+we3RQLLwA/cYOW6lzd7g4Gx3lvTrUvNfk9saAhirWFQXgtWgSSIVqutKMrDo4effPYpIaQsi8XCKaqCSkKW5+ejc1mSIIQEQWga7Vs337q6t9s1dXt0+pc//x3W3NHJfDh1g2t4E6ugDZZlcsno9Nb3BLGxmC/mk1lWwgYRb+zfEijX1HVVUf59925eF42+9c87d7IkGw1Hmq4TgFBDUw1Dswy13zdeHn0+X7hpzBAkW5fXn02nTsWentiE8O+//3tJ1nzP1zRdklRCSUlJGFeNtlEWmSLz+3sbR4cHKE977Va+1ieQBXGEasYgQqIoAYbmtvvk6XN3lSZ5npXFcHRx/9MHx89Gz47O8wS0NGt4fjFZ2BViSlOuYeWFbpznYqPp+OEqSnTTsnrd5ewicMZtlb99/YrREAjGqCrrk5PRZGov5vMnnz8rGUCQZVWR+UUNsT1bDdbaAOB79+7JDeHG2zcxgVkajM9fOouFrDb1Vnvl+VMO11UW51kcupPzF5CQlmlQVJKqqqbTmeuu6rqKoiTPSwBhDRljDAAMAJxNJ5QKhLI7d9Nbt98Cn5Wz8ci+OJM5lMZRmJS3vvfOm9f3GcujZIVgycuS2euHcbRYeTljpK7rIAjDIAYAMoAAQADWADAAAWAMwros0+XSlmWCkPXJ3Q9fHg5dx9le7//8Jz/OXPuLJwdVEg4scW29q/BilMHTCUwqEGSVH2YlIF8Bh4EaAAhADQAAjAH2ql0DBgDAKy/b3lLWu93/HT6wj74MGPjZL3/x7k/fS9xnv/ndbxXNLBOnTJdU4pI0PDg4nE7tOM1dP0QYv040Br5TEAII2+0WgojDeGe95VaFt3I+/Pj+m1c7P7pxi1N0ENn25Gy8sB88enJ8eFzUrKwBYjD0IwRf03faMwZkVbiYnH3wwT8Qpp2uIfLg/r2P/vDHPz0+Hs6DeGmPozStER1e2CenY4KwrjbMtqFIsirLxDBMd7ms6goAACF8BdLXUiHAGMZ1UaShXwqd9ZZmNNY7bwAdcd133n5n5a9eToe6LLTbrf1rt9TW2pWz0/licXJ2DmrkeyuyuTUoytzzfMAAhAACxr7BNAAQIgABwcww9ZbCX1rfuHHzapw4V3dvXLn6w7Zl1jDrWRYoY5EjTUQlRceAze15nhasYrqiEanBb+1ueG44t5dZEpdFBgH4+iGAANUQgmZTvv7W/ub2+vdv395ZX0uSsNsfqKrFIE+ArEqCMzp8efKQCERrtw1NbDZU0+zM7aVvL8l4PO2v9bZ3BnEcnp0Mx+d2nhWEEo6jYRAWJcOYXN7a/vWv3tu7stPv9kWqQMwAqgEkFYNJHAyff3H84P7pwUNDk61uRzINy9JXcWLbU1GhxJ45ptWWZYoI2tvf2Ni47DiOIJJ2W7dtezrxZhOn1720s73ZM9ocRBgRAKskDZcrT1WbVZW9OD388OOPSte5ubtJ6toJ/db6NoQ1JExpKiQKk/PhBGOEaSUIclGXgsKbltbQRKu/u7lTHj49liQwPj+WcMpBBAHjRBKn0Xgy15td3TDjuDg8mW12La8k6cLnkqyAiiiohEqn4xNS5uVkNK3L2rQMyjMiUkKhF/gVyCRF4ERxbcvMq+CT//xr+LLTt4wsWgKQq6raX9vFZfr04YOlu2xfsl5MJvPlzFKlQbfPGQRTOU/R+XBOAKvLvF7YDqhgo611Db2qisnEdj0qKYIgU54iInGfH375+NHj3a3tK3vbGz3DW84Fydve3eP9lNDKNKnrJjnkIsJ/OV4dTB9znHBwcHT2fPLVJudZPptOIUWSK8dJhBCqCoYBlTip0ZCSJIuTHBTV2Lbbhj4Y9CquWQiWB1WtM4gf/rcsKtPoQEAZ4/womk3OpjPbXwV5Xn19ixgrq2o8Gvuh32zprXaTI5gCEq0iCpEiShhTUW7UCD49OhrPFoONq5VcOGwswhIjIc9AXeE0KZzFYrFY2rYTBlFdAwjw/wEVlkAkYT/YjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./data/train/dog/3133.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyyFzY5r6yTV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKA4sorLEqqk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cross_entropy'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-54zhck2ErmK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# outputs.shape\n",
    "from collections import OrderedDict\n",
    "\n",
    "inputs = torch.randn((1,3,32,32))\n",
    "\n",
    "inputs = inputs.cuda()\n",
    "targets_fast = torch.tensor([1])\n",
    "# net = get_model()\n",
    "\n",
    "outputs = net.forward(inputs)\n",
    "#net.eval()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "fast_loss = criterion(outputs,targets_fast.cuda())\n",
    "\n",
    "grads = torch.autograd.grad(fast_loss, net.parameters(), create_graph=True, retain_graph=True, only_inputs=True)\n",
    "with torch.no_grad():\n",
    "    fast_weights = OrderedDict((name, param - 0.2*grad) for ((name, param), grad) in zip(net.named_parameters(), grads))\n",
    "# for grad in grads:\n",
    "#     grad.requires_grad = False  \n",
    "fast_out = net.forward(inputs,fast_weights)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet34'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "baseline_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2bb2a28a69994812a4f3b0c44c929952": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3271b94bca1f4e5cb9c52119fa0bf3c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e1accdd5a2eb47dea84e5eb84b6da723",
       "IPY_MODEL_3bde9f328709474cad96f8e0ab143cec"
      ],
      "layout": "IPY_MODEL_8be9ca007a2e4dafa1eebbfdb43a6aca"
     }
    },
    "3644e0b4152a4daf86228ca51f50afc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bde9f328709474cad96f8e0ab143cec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e028b7fe53434234972a266b9d093484",
      "placeholder": "​",
      "style": "IPY_MODEL_3644e0b4152a4daf86228ca51f50afc8",
      "value": " 97.8M/97.8M [00:00&lt;00:00, 161MB/s]"
     }
    },
    "8be9ca007a2e4dafa1eebbfdb43a6aca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce8de694a4d14ac599683e6a5425f92f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e028b7fe53434234972a266b9d093484": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1accdd5a2eb47dea84e5eb84b6da723": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce8de694a4d14ac599683e6a5425f92f",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2bb2a28a69994812a4f3b0c44c929952",
      "value": 102502400
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
