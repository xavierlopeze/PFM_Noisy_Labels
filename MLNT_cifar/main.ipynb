{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2AiEquVKc481","colab_type":"code","outputId":"481fed14-7791-45fa-d6f8-ad818098d771","executionInfo":{"status":"ok","timestamp":1588443678135,"user_tz":-120,"elapsed":11474,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install wandb"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/c9/ebbcefa6ef2ba14a7c62a4ee4415a5fecef8fac5e4d1b4e22af26fd9fe22/wandb-0.8.35-py2.py3-none-any.whl (1.4MB)\n","\r\u001b[K     |▎                               | 10kB 29.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |████                            | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▌                           | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 481kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 491kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 501kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 512kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 522kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 532kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 542kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 552kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 563kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 573kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 583kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 593kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 604kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 614kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 624kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 634kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 645kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 655kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 665kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 675kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 686kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 696kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 706kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 716kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 727kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 737kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 747kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 757kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 768kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 778kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 788kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 798kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 808kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 819kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 829kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 839kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 849kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 860kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 870kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 880kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 890kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 901kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 911kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 921kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 931kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 942kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 952kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 962kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 972kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 983kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 993kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.0MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.0MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.0MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.0MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4MB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 15.4MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/7e/19545324e83db4522b885808cd913c3b93ecc0c88b03e037b78c6a417fa8/sentry_sdk-0.14.3-py2.py3-none-any.whl (103kB)\n","\u001b[K     |████████████████████████████████| 112kB 72.6MB/s \n","\u001b[?25hCollecting gql==0.2.0\n","  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/1a/0df85d2bddbca33665d2148173d3281b290ac054b5f50163ea735740ac7b/GitPython-3.1.1-py3-none-any.whl (450kB)\n","\u001b[K     |████████████████████████████████| 460kB 68.8MB/s \n","\u001b[?25hCollecting watchdog>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n","\u001b[K     |████████████████████████████████| 102kB 14.9MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.4.5.1)\n","Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n","Collecting graphql-core<2,>=0.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n","\u001b[K     |████████████████████████████████| 71kB 12.0MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.9)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/52/ca35448b56c53a079d3ffe18b1978c6e424f6d4df02404877094c89f5bfb/gitdb-4.0.4-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.0MB/s \n","\u001b[?25hCollecting pathtools>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/27/b1/e379cfb7c07bbf8faee29c4a1a2469dbea525f047c2b454c4afdefa20a30/smmap-3.0.2-py2.py3-none-any.whl\n","Building wheels for collected packages: subprocess32, gql, watchdog, graphql-core, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=d96e2e0adfb62c7a53c9c0a7b3c02c11d3dc52f89d66ccc5b345a7f30dc705c6\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=192105a51cb6fb305dbb2db9b7c98ea5fc73667217a622291a7dd209c87f2fc1\n","  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=1661a5ad6342e0c16ac6aac032f6098db3f86bce1ab0ccc2fa770f11e20332c2\n","  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n","  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=3fb7d5c924f0f58e226ae47534cac2b0b1b447ffd408a80686d253256e04939e\n","  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=0faaa13f9dc3889a591a0c2dd9086db09c50f267c7ebf60345b165836ee5a876\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built subprocess32 gql watchdog graphql-core pathtools\n","Installing collected packages: shortuuid, subprocess32, sentry-sdk, graphql-core, gql, configparser, smmap, gitdb, GitPython, pathtools, watchdog, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.1 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.4 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.14.3 shortuuid-1.0.1 smmap-3.0.2 subprocess32-3.5.4 wandb-0.8.35 watchdog-0.10.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88ezc8iRdkqg","colab_type":"code","outputId":"1423399d-87b5-4cca-a926-0c6dbead0c5e","executionInfo":{"status":"ok","timestamp":1588443693837,"user_tz":-120,"elapsed":27150,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["!wandb login"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: dff003aa03e7d25df35a840b6f0660ae9675efb4\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8skRpihGdp1q","colab_type":"code","outputId":"685e7be0-eeb6-4e12-e168-4546c51ba571","executionInfo":{"status":"ok","timestamp":1588443695192,"user_tz":-120,"elapsed":28486,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["#GPU INFO\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sat May  2 18:21:34 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"csakjx4mdrs5","colab_type":"code","outputId":"7c0be341-0dbe-41fe-bdfa-b9be504ed7d8","executionInfo":{"status":"ok","timestamp":1588443716441,"user_tz":-120,"elapsed":49719,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zoV2tev1jHbQ","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/MLNT_cifar')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xq88YZuGhRTA","colab_type":"code","outputId":"887fa9cc-8d11-4ae4-9c24-782cbf49836d","executionInfo":{"status":"ok","timestamp":1588443731327,"user_tz":-120,"elapsed":64575,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["# Pytorch libraries\n","import torch\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","# Internal files\n","import config\n","import dataloader\n","import models\n","# from baseline import get_model, save_checkpoint\n","\n","import math\n","import os\n","import sys\n","import time\n","from collections import OrderedDict\n","import random\n","\n","import wandb\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","noise file noisy_label_kv.txt generated with noise: 0.5\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://app.wandb.ai/xavierlopeze/Cifar_Experiment\" target=\"_blank\">https://app.wandb.ai/xavierlopeze/Cifar_Experiment</a><br/>\n","                Run page: <a href=\"https://app.wandb.ai/xavierlopeze/Cifar_Experiment/runs/1irk0t1w\" target=\"_blank\">https://app.wandb.ai/xavierlopeze/Cifar_Experiment/runs/1irk0t1w</a><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"tsMIDod2mpPz","colab_type":"code","colab":{}},"source":["def get_model():\n","\n","    # Get model from config\n","    if config.model == \"resnet18\":\n","        model = models.resnet18(pretrained=config.pretrained)\n","    elif config.model == \"resnet34\":\n","        model = models.resnet34(pretrained=config.pretrained)\n","    elif config.model == 'resnet50':\n","        model = models.resnet50(pretrained=config.pretrained)\n","    elif config.model == \"resnet101\":\n","        model = models.resnet101(pretrained=config.pretrained)\n","    elif config.model == \"resnet152\":\n","        model = models.resnet152(pretrained=config.pretrained)\n","    elif config.model == \"resnext50_32x4d\":\n","        model = models.resnet34(pretrained=config.pretrained)\n","    elif config.model == 'resnext101_32x8d':\n","        model = models.resnet50(pretrained=config.pretrained)\n","    elif config.model == \"wide_resnet50_2\":\n","        model = models.resnet101(pretrained=config.pretrained)\n","    elif config.model == \"wide_resnet101_2\":\n","        model = models.resnet152(pretrained=config.pretrained)\n","    else:\n","        raise ValueError('%s not supported'.format(config.model))\n","\n","    # Initialize fc layer\n","    (in_features, out_features) = model.fc.in_features, model.fc.out_features\n","    model.fc = torch.nn.Linear(in_features, out_features)\n","    return model\n","\n","\n","\n","def save_checkpoint(state, filename='checkpoint.pth.tar'):\n","    torch.save(state, filename)\n","    if config.use_wandb == True:\n","        wandb.save(filename)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UG1lpyQugVk3","colab_type":"code","colab":{}},"source":["def scheduler(epoch: int):\n","    global lr\n","    lr = config.lr\n","    if epoch > config.start_epoch:\n","        lr = lr / 10.0\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","\n","\n","# Training\n","def train(epoch):\n","    global init\n","    net.train()\n","    tch_net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    scheduler(epoch)\n","\n","\n","    # ramp up meta-learning rate and EMA decay\n","    if epoch <= config.param_epoch:\n","        u = epoch/config.param_epoch\n","        meta_lr = config.meta_lr*math.exp(-5*(1-u)**2)\n","    else:\n","        meta_lr = config.meta_lr\n","        config.eps = 0.999\n","\n","    for step, (inputs, targets) in enumerate(train_loader):\n","        init_time = time.time()\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","\n","        class_loss = criterion(outputs, targets)\n","        class_loss.backward(retain_graph=True)\n","        \n","\n","        if step > config.start_iter or epoch > 1:\n","        #if step > 0 or epoch > 0:\n","\n","            # if step > config.mid_iter or epoch > 1:\n","            #     # config.eps = 0.999\n","            #     alpha = config.alpha \n","            # else:\n","            #     u = (step - config.start_iter)/(config.mid_iter - config.start_iter)\n","            #     alpha = config.alpha*math.exp(-5*(1-u)**2)\n","            alpha = config.alpha\n","\n","            if init:\n","                init = False\n","                for param, param_tch in zip(net.parameters(), tch_net.parameters()):\n","                    param_tch.data.copy_(param.data)\n","            else:\n","                for param, param_tch in zip(net.parameters(), tch_net.parameters()):\n","                    param_tch.data.mul_(config.eps).add_((1-config.eps), param.data)\n","\n","            _, feats = pretrain_net(inputs, get_feat=True)\n","            tch_outputs = tch_net(inputs, get_feat=False)\n","            p_tch = F.softmax(tch_outputs, dim=1)\n","            p_tch.detach_()\n","\n","            for i in range(config.num_fast):\n","                targets_fast = targets.clone()\n","                randidx = torch.randperm(targets.size(0))\n","                for n in range(int(targets.size(0)*config.perturb_ratio)):\n","                    num_neighbor = 10\n","                    idx = randidx[n]\n","                    feat = feats[idx]\n","                    feat.view(1, feat.size(0))\n","                    feat.data = feat.data.expand(targets.size(0), feat.size(0))\n","                    dist = torch.sum((feat-feats)**2, dim=1)\n","                    _, neighbor = torch.topk(dist.data, num_neighbor+1, largest=False)\n","                    targets_fast[idx] = targets[neighbor[random.randint(1, num_neighbor)]]\n","\n","                fast_loss = criterion(outputs, targets_fast)\n","\n","                grads = torch.autograd.grad(fast_loss, net.parameters(),\n","                                            create_graph=False,\n","                                            retain_graph=True,\n","                                            only_inputs=True)\n","\n","                fast_weights = OrderedDict(\n","                    (name, param - meta_lr*grad)\n","                    for ((name, param), grad) in zip(net.named_parameters(), grads))\n","\n","                fast_out = net.forward(inputs,fast_weights)\n","\n","                logp_fast = F.log_softmax(fast_out,dim=1)\n","                consistent_loss = consistent_criterion(logp_fast, p_tch)\n","                consistent_loss = consistent_loss*alpha/config.num_fast\n","                consistent_loss.backward()\n","\n","        optimizer.step()\n","\n","        # train_loss += class_loss.data.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","\n","        # Grab training results\n","        sys.stdout.write('\\r')\n","        sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%, time: %.3f'\n","              %(epoch, config.num_epochs, step+1, (len(train_loader.dataset)//config.batch_size)+1, class_loss.data.item(), 100.*correct/total,time.time() - init_time))\n","        sys.stdout.flush()\n","\n","\n","\n","def valid(epoch, network):\n","    global best_acc\n","    network.eval()\n","    # val_loss = 0\n","    correct = 0\n","    total = 0\n","    for step, (inputs, targets) in enumerate(valid_loader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        with torch.no_grad():\n","            outputs = network(inputs)\n","            loss = criterion(outputs, targets)\n","\n","        # valid_loss += loss.data.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","\n","        # Grab validation results\n","        valid_acc = 100. * correct / total\n","      # valid_results = (\"| Epoch: {}/{}, val_loss: {:.3f}, val_acc: {:.3f}, \"\n","      #                 \"lr: {:.6f}\".format(epoch,\n","      #                                     config.num_epochs,\n","      #                                     loss.data.item(),\n","      #                                     valid_acc,\n","      #                                     lr))\n","        # Grab validation results\n","        valid_results = (\"| Epoch: {}/{}, val_loss: {:.3f}, val_acc: {:.3f}, \"\"lr: {:.6f}\".format(epoch,config.num_epochs,loss.data.item(),valid_acc,lr))\n","        record.write(valid_results + '\\n')\n","        record.flush()\n","       \n","        \n","\n","    # Save checkpoint when best model\n","    if valid_acc > best_acc:\n","        best_acc = valid_acc\n","        print('| Saving Best Model ...', end=\"\\r\")\n","        save_point = config.drive_dir + '/checkpoint/' + config.id + '.pth.tar' \n","        save_checkpoint({\n","            'state_dict': network.state_dict(),\n","            'best_acc': best_acc,\n","        }, save_point)\n","     \n","    wandb.log({'epoch': epoch, 'accy_val' : best_acc })\n","\n","    return valid_results\n","\n","\n","def test():\n","    test_net.eval()\n","    # test_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(valid_loader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        with torch.no_grad():\n","            outputs = test_net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","        # test_loss += loss.data.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","\n","    # Grab validation results\n","    test_acc = 100. * correct/total\n","    test_results = \"| test_loss: {:.3f}, test_acc: {:.3f}\".format(\n","        loss.data.item(), test_acc)\n","    record.write(test_results)\n","    record.flush()\n","\n","    print(test_results)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEBEekTkLEP4","colab_type":"code","colab":{}},"source":["def save_weights(epoch):\n","        print('| Saving Weights student ...', end=\"\\r\")\n","        save_point = config.drive_dir + '/checkpoint/' + config.id + '_student_' + str(epoch) + '.pth.tar'\n","        save_checkpoint({'state_dict': net.state_dict(), }, save_point)\n","\n","        print('| Saving Weights teacher ...', end=\"\\r\")\n","        save_point = config.drive_dir + '/checkpoint/' + config.id + '_teacher_' + str(epoch) + '.pth.tar'\n","        save_checkpoint({'state_dict': tch_net.state_dict(), }, save_point)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9mjWKzpX9L_W","outputId":"1d71e623-01f6-4d5b-d89f-9050bffc75f5","executionInfo":{"status":"ok","timestamp":1588443749722,"user_tz":-120,"elapsed":80862,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"colab":{"base_uri":"https://localhost:8080/","height":280}},"source":["# Checkpoint dir.\n","record = open(config.drive_dir + '/checkpoint/' + config.checkpoint + '_test.txt', 'w')\n","record.write('noise_rate=%s\\n' % config.noise_rate)\n","record.flush()\n","\n","# Get the original_dataset\n","loader = dataloader.KeyDataLoader()\n","train_loader, valid_loader, test_loader = loader.run()\n","\n","# Hyper Parameter settings\n","random.seed(config.seed)\n","# torch.cuda.set_device(config.gpuid)\n","torch.manual_seed(config.seed)\n","torch.cuda.manual_seed_all(config.seed)\n","use_cuda = torch.cuda.is_available()\n","\n","# Networks setup\n","print('\\nModel setup')\n","print('| Building network: {}'.format(config.model))\n","net = get_model()\n","tch_net = get_model()\n","pretrain_net = get_model()\n","test_net = get_model()\n","\n","print('| load pretrained net. from checkpoint...')\n","checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.checkpoint + '.pth.tar')\n","pretrain_net.load_state_dict(checkpoint['state_dict'])\n","\n","if use_cuda:\n","    net.cuda()\n","    tch_net.cuda()\n","    pretrain_net.cuda()\n","    test_net.cuda()\n","    cudnn.benchmark = True\n","pretrain_net.eval()\n","\n","for param in tch_net.parameters():\n","    param.requires_grad = False\n","for param in pretrain_net.parameters():\n","    param.requires_grad = False\n","\n","# Instantiate a loss function.\n","criterion = torch.nn.CrossEntropyLoss()\n","consistent_criterion = torch.nn.KLDivLoss()\n","\n","# Instantiate an optimizer to train the model\n","optimizer = torch.optim.SGD(\n","    net.parameters(), lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n","\n","print('\\nTraining model')\n","print('| Training Epochs = ' + str(config.num_epochs))\n","print('| Initial Learning Rate = ' + str(config.lr))\n","print('| Optimizer = ' + str(config.optimizer_type))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Model setup\n","| Building network: resnet34\n"],"name":"stdout"},{"output_type":"stream","text":["/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/MLNT_cifar/models/resnet.py:122: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(m.weight, mode='fan_out')\n","/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/MLNT_cifar/models/resnet.py:124: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(m.weight, 1)\n","/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/MLNT_cifar/models/resnet.py:125: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(m.bias, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["| load pretrained net. from checkpoint...\n","\n","Training model\n","| Training Epochs = 120\n","| Initial Learning Rate = 0.2\n","| Optimizer = SGD\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bZRHtbXGmqnM","colab_type":"code","outputId":"77bfcee4-96fa-46fc-a15f-8bb8a42b82f4","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["init = True\n","best_acc = 0\n","for epoch in range(1, 1 + config.num_epochs):\n","    train(epoch)\n","    # Student validation\n","    std_results = valid(epoch, net)\n","    record.write(std_results + '\\n')\n","    print(std_results)\n","    # Teacher validation\n","    tch_results = valid(epoch, tch_net)\n","    record.write(tch_results + '\\n')\n","    record.flush()\n","    print(tch_results)\n","\n","    save_weights(epoch)\n","\n","print('\\nTesting model')\n","checkpoint = torch.load('./checkpoint/%s.pth.tar' % config.id)\n","test_net.load_state_dict(checkpoint['state_dict'])\n","test()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["| Epoch: 1/120, val_loss: 2.527, val_acc: 10.560, lr: 0.200000\n","| Epoch: 1/120, val_loss: 23.725, val_acc: 0.000, lr: 0.200000\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["\r| Epoch [  2/120] Iter[  1/352]\t\tLoss: 2.4118 Acc@1: 7.031%, time: 2.495"],"name":"stdout"},{"output_type":"stream","text":["/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n"],"name":"stderr"},{"output_type":"stream","text":["| Epoch: 2/120, val_loss: 2.020, val_acc: 11.460, lr: 0.200000\n","| Epoch: 2/120, val_loss: 2.318, val_acc: 14.060, lr: 0.200000\n","| Epoch: 3/120, val_loss: 2.438, val_acc: 14.200, lr: 0.200000\n","| Epoch: 3/120, val_loss: 2.139, val_acc: 17.020, lr: 0.200000\n","| Epoch [  4/120] Iter[352/352]\t\tLoss: 2.2953 Acc@1: 12.771%, time: 1.171| Epoch: 4/120, val_loss: 2.096, val_acc: 14.120, lr: 0.200000\n","| Epoch: 4/120, val_loss: 1.957, val_acc: 23.400, lr: 0.200000\n","| Epoch [  5/120] Iter[352/352]\t\tLoss: 2.2953 Acc@1: 15.276%, time: 1.173| Epoch: 5/120, val_loss: 2.108, val_acc: 12.660, lr: 0.200000\n","| Epoch: 5/120, val_loss: 2.000, val_acc: 28.840, lr: 0.200000\n","| Epoch [  6/120] Iter[352/352]\t\tLoss: 2.2997 Acc@1: 16.338%, time: 1.175| Epoch: 6/120, val_loss: 2.200, val_acc: 19.680, lr: 0.200000\n","| Epoch: 6/120, val_loss: 1.962, val_acc: 31.520, lr: 0.200000\n","| Epoch [  7/120] Iter[352/352]\t\tLoss: 2.2929 Acc@1: 17.184%, time: 1.172| Epoch: 7/120, val_loss: 2.051, val_acc: 22.280, lr: 0.200000\n","| Epoch: 7/120, val_loss: 2.003, val_acc: 33.840, lr: 0.200000\n","| Epoch [  8/120] Iter[352/352]\t\tLoss: 2.2700 Acc@1: 18.693%, time: 1.177| Epoch: 8/120, val_loss: 2.272, val_acc: 18.740, lr: 0.200000\n","| Epoch: 8/120, val_loss: 1.910, val_acc: 36.360, lr: 0.200000\n","| Epoch [  9/120] Iter[352/352]\t\tLoss: 2.1642 Acc@1: 19.791%, time: 1.172| Epoch: 9/120, val_loss: 1.997, val_acc: 26.280, lr: 0.200000\n","| Epoch: 9/120, val_loss: 1.813, val_acc: 39.880, lr: 0.200000\n","| Epoch [ 10/120] Iter[352/352]\t\tLoss: 2.3389 Acc@1: 20.527%, time: 1.171| Epoch: 10/120, val_loss: 2.127, val_acc: 29.340, lr: 0.200000\n","| Epoch: 10/120, val_loss: 1.843, val_acc: 42.300, lr: 0.200000\n","| Epoch [ 11/120] Iter[352/352]\t\tLoss: 2.3081 Acc@1: 21.167%, time: 1.176| Epoch: 11/120, val_loss: 2.236, val_acc: 26.440, lr: 0.200000\n","| Epoch: 11/120, val_loss: 1.761, val_acc: 42.520, lr: 0.200000\n","| Epoch [ 12/120] Iter[352/352]\t\tLoss: 2.1746 Acc@1: 22.104%, time: 1.177| Epoch: 12/120, val_loss: 2.284, val_acc: 33.500, lr: 0.200000\n","| Epoch: 12/120, val_loss: 1.855, val_acc: 43.740, lr: 0.200000\n","| Epoch [ 13/120] Iter[352/352]\t\tLoss: 2.1949 Acc@1: 22.813%, time: 1.175| Epoch: 13/120, val_loss: 2.364, val_acc: 36.320, lr: 0.200000\n","| Epoch: 13/120, val_loss: 1.811, val_acc: 44.900, lr: 0.200000\n","| Epoch [ 14/120] Iter[352/352]\t\tLoss: 2.0391 Acc@1: 23.800%, time: 1.177| Epoch: 14/120, val_loss: 2.140, val_acc: 36.200, lr: 0.200000\n","| Epoch: 14/120, val_loss: 1.692, val_acc: 47.280, lr: 0.200000\n","| Epoch [ 15/120] Iter[352/352]\t\tLoss: 2.1475 Acc@1: 24.682%, time: 1.179| Epoch: 15/120, val_loss: 1.568, val_acc: 41.160, lr: 0.200000\n","| Epoch: 15/120, val_loss: 1.660, val_acc: 49.480, lr: 0.200000\n","| Epoch [ 16/120] Iter[352/352]\t\tLoss: 2.1376 Acc@1: 24.984%, time: 1.174| Epoch: 16/120, val_loss: 2.099, val_acc: 36.280, lr: 0.200000\n","| Epoch: 16/120, val_loss: 1.620, val_acc: 51.220, lr: 0.200000\n","| Epoch [ 17/120] Iter[352/352]\t\tLoss: 2.1390 Acc@1: 25.842%, time: 1.171| Epoch: 17/120, val_loss: 2.095, val_acc: 44.660, lr: 0.200000\n","| Epoch: 17/120, val_loss: 1.671, val_acc: 53.040, lr: 0.200000\n","| Epoch [ 18/120] Iter[352/352]\t\tLoss: 2.2032 Acc@1: 26.427%, time: 1.176| Epoch: 18/120, val_loss: 2.188, val_acc: 39.440, lr: 0.200000\n","| Epoch: 18/120, val_loss: 1.587, val_acc: 54.740, lr: 0.200000\n","| Epoch [ 19/120] Iter[352/352]\t\tLoss: 2.1835 Acc@1: 27.042%, time: 1.181| Epoch: 19/120, val_loss: 2.161, val_acc: 39.980, lr: 0.200000\n","| Epoch: 19/120, val_loss: 1.488, val_acc: 55.820, lr: 0.200000\n","| Epoch [ 20/120] Iter[352/352]\t\tLoss: 2.1657 Acc@1: 27.602%, time: 1.182| Epoch: 20/120, val_loss: 2.095, val_acc: 43.960, lr: 0.200000\n","| Epoch: 20/120, val_loss: 1.397, val_acc: 58.180, lr: 0.200000\n","| Epoch [ 21/120] Iter[352/352]\t\tLoss: 2.1314 Acc@1: 28.822%, time: 1.175| Epoch: 21/120, val_loss: 1.604, val_acc: 51.780, lr: 0.200000\n","| Epoch: 21/120, val_loss: 1.346, val_acc: 58.920, lr: 0.200000\n","| Epoch [ 22/120] Iter[352/352]\t\tLoss: 2.1561 Acc@1: 29.682%, time: 1.177| Epoch: 22/120, val_loss: 1.420, val_acc: 47.300, lr: 0.200000\n","| Epoch: 22/120, val_loss: 1.314, val_acc: 60.060, lr: 0.200000\n","| Epoch [ 23/120] Iter[352/352]\t\tLoss: 2.2123 Acc@1: 30.660%, time: 1.176| Epoch: 23/120, val_loss: 1.421, val_acc: 53.180, lr: 0.200000\n","| Epoch: 23/120, val_loss: 1.297, val_acc: 61.940, lr: 0.200000\n","| Epoch [ 24/120] Iter[352/352]\t\tLoss: 2.0120 Acc@1: 31.124%, time: 1.173| Epoch: 24/120, val_loss: 1.007, val_acc: 48.580, lr: 0.200000\n","| Epoch: 24/120, val_loss: 1.203, val_acc: 63.360, lr: 0.200000\n","| Epoch [ 25/120] Iter[352/352]\t\tLoss: 2.1451 Acc@1: 31.987%, time: 1.174| Epoch: 25/120, val_loss: 0.638, val_acc: 54.240, lr: 0.200000\n","| Epoch: 25/120, val_loss: 1.136, val_acc: 64.860, lr: 0.200000\n","| Epoch [ 26/120] Iter[352/352]\t\tLoss: 2.0908 Acc@1: 32.884%, time: 1.172| Epoch: 26/120, val_loss: 0.834, val_acc: 56.660, lr: 0.200000\n","| Epoch: 26/120, val_loss: 1.037, val_acc: 66.960, lr: 0.200000\n","| Epoch [ 27/120] Iter[352/352]\t\tLoss: 1.9739 Acc@1: 33.396%, time: 1.179| Epoch: 27/120, val_loss: 1.041, val_acc: 55.480, lr: 0.200000\n","| Epoch: 27/120, val_loss: 1.020, val_acc: 68.120, lr: 0.200000\n","| Epoch [ 28/120] Iter[352/352]\t\tLoss: 2.1655 Acc@1: 33.722%, time: 1.178| Epoch: 28/120, val_loss: 0.986, val_acc: 44.640, lr: 0.200000\n","| Epoch: 28/120, val_loss: 0.945, val_acc: 69.700, lr: 0.200000\n","| Epoch [ 29/120] Iter[352/352]\t\tLoss: 2.0563 Acc@1: 34.307%, time: 1.177| Epoch: 29/120, val_loss: 1.187, val_acc: 54.260, lr: 0.200000\n","| Epoch: 29/120, val_loss: 0.943, val_acc: 70.900, lr: 0.200000\n","| Epoch [ 30/120] Iter[352/352]\t\tLoss: 2.1564 Acc@1: 34.476%, time: 1.178| Epoch: 30/120, val_loss: 0.672, val_acc: 55.160, lr: 0.200000\n","| Epoch: 30/120, val_loss: 0.920, val_acc: 71.760, lr: 0.200000\n","| Epoch [ 31/120] Iter[352/352]\t\tLoss: 2.1156 Acc@1: 35.084%, time: 1.174| Epoch: 31/120, val_loss: 0.720, val_acc: 60.380, lr: 0.200000\n","| Epoch: 31/120, val_loss: 0.893, val_acc: 72.780, lr: 0.200000\n","| Epoch [ 32/120] Iter[352/352]\t\tLoss: 2.0078 Acc@1: 35.167%, time: 1.180| Epoch: 32/120, val_loss: 0.797, val_acc: 54.880, lr: 0.200000\n","| Epoch: 32/120, val_loss: 0.875, val_acc: 73.840, lr: 0.200000\n","| Epoch [ 33/120] Iter[352/352]\t\tLoss: 2.0904 Acc@1: 35.784%, time: 1.179| Epoch: 33/120, val_loss: 1.207, val_acc: 56.440, lr: 0.200000\n","| Epoch: 33/120, val_loss: 0.857, val_acc: 74.680, lr: 0.200000\n","| Epoch [ 34/120] Iter[352/352]\t\tLoss: 1.8749 Acc@1: 36.131%, time: 1.177| Epoch: 34/120, val_loss: 0.775, val_acc: 61.780, lr: 0.200000\n","| Epoch: 34/120, val_loss: 0.809, val_acc: 75.620, lr: 0.200000\n","| Epoch [ 35/120] Iter[352/352]\t\tLoss: 2.0514 Acc@1: 36.482%, time: 1.180| Epoch: 35/120, val_loss: 0.913, val_acc: 63.260, lr: 0.200000\n","| Epoch: 35/120, val_loss: 0.787, val_acc: 76.140, lr: 0.200000\n","| Epoch [ 36/120] Iter[352/352]\t\tLoss: 1.8610 Acc@1: 36.844%, time: 1.178| Epoch: 36/120, val_loss: 0.960, val_acc: 64.440, lr: 0.200000\n","| Epoch: 36/120, val_loss: 0.822, val_acc: 77.060, lr: 0.200000\n","| Epoch [ 37/120] Iter[352/352]\t\tLoss: 2.1455 Acc@1: 37.284%, time: 1.183| Epoch: 37/120, val_loss: 1.218, val_acc: 60.320, lr: 0.200000\n","| Epoch: 37/120, val_loss: 0.850, val_acc: 77.500, lr: 0.200000\n","| Epoch [ 38/120] Iter[352/352]\t\tLoss: 2.0266 Acc@1: 37.436%, time: 1.183| Epoch: 38/120, val_loss: 0.693, val_acc: 63.700, lr: 0.200000\n","| Epoch: 38/120, val_loss: 0.878, val_acc: 78.180, lr: 0.200000\n","| Epoch [ 39/120] Iter[352/352]\t\tLoss: 2.0061 Acc@1: 37.669%, time: 1.181| Epoch: 39/120, val_loss: 0.768, val_acc: 55.060, lr: 0.200000\n","| Epoch: 39/120, val_loss: 0.857, val_acc: 78.760, lr: 0.200000\n","| Epoch [ 40/120] Iter[352/352]\t\tLoss: 2.1241 Acc@1: 38.193%, time: 1.181| Epoch: 40/120, val_loss: 0.693, val_acc: 60.180, lr: 0.200000\n","| Epoch: 40/120, val_loss: 0.801, val_acc: 79.440, lr: 0.200000\n","| Epoch [ 41/120] Iter[352/352]\t\tLoss: 1.9985 Acc@1: 38.553%, time: 1.181| Epoch: 41/120, val_loss: 0.824, val_acc: 62.820, lr: 0.200000\n","| Epoch: 41/120, val_loss: 0.797, val_acc: 79.780, lr: 0.200000\n","| Epoch [ 42/120] Iter[352/352]\t\tLoss: 1.9808 Acc@1: 38.773%, time: 1.180| Epoch: 42/120, val_loss: 1.391, val_acc: 63.060, lr: 0.200000\n","| Epoch: 42/120, val_loss: 0.811, val_acc: 80.180, lr: 0.200000\n","| Epoch [ 43/120] Iter[352/352]\t\tLoss: 1.8237 Acc@1: 39.024%, time: 1.185| Epoch: 43/120, val_loss: 0.765, val_acc: 64.280, lr: 0.200000\n","| Epoch: 43/120, val_loss: 0.812, val_acc: 80.460, lr: 0.200000\n","| Epoch [ 44/120] Iter[352/352]\t\tLoss: 1.7656 Acc@1: 39.140%, time: 1.180| Epoch: 44/120, val_loss: 0.457, val_acc: 66.600, lr: 0.200000\n","| Epoch: 44/120, val_loss: 0.791, val_acc: 81.060, lr: 0.200000\n","| Epoch [ 45/120] Iter[352/352]\t\tLoss: 1.9357 Acc@1: 39.378%, time: 1.173| Epoch: 45/120, val_loss: 1.724, val_acc: 48.960, lr: 0.200000\n","| Epoch: 45/120, val_loss: 0.791, val_acc: 81.300, lr: 0.200000\n","| Epoch [ 46/120] Iter[352/352]\t\tLoss: 2.0684 Acc@1: 39.687%, time: 1.180| Epoch: 46/120, val_loss: 1.299, val_acc: 57.720, lr: 0.200000\n","| Epoch: 46/120, val_loss: 0.764, val_acc: 81.680, lr: 0.200000\n","| Epoch [ 47/120] Iter[352/352]\t\tLoss: 1.7934 Acc@1: 39.773%, time: 1.181| Epoch: 47/120, val_loss: 1.072, val_acc: 62.800, lr: 0.200000\n","| Epoch: 47/120, val_loss: 0.818, val_acc: 82.120, lr: 0.200000\n","| Epoch [ 48/120] Iter[352/352]\t\tLoss: 1.9767 Acc@1: 39.878%, time: 1.180| Epoch: 48/120, val_loss: 2.355, val_acc: 44.560, lr: 0.200000\n","| Epoch: 48/120, val_loss: 0.789, val_acc: 82.460, lr: 0.200000\n","| Epoch [ 49/120] Iter[352/352]\t\tLoss: 2.0008 Acc@1: 40.280%, time: 1.184| Epoch: 49/120, val_loss: 2.382, val_acc: 36.120, lr: 0.200000\n","| Epoch: 49/120, val_loss: 0.804, val_acc: 82.860, lr: 0.200000\n","| Epoch [ 50/120] Iter[352/352]\t\tLoss: 1.8752 Acc@1: 40.491%, time: 1.185| Epoch: 50/120, val_loss: 1.911, val_acc: 43.940, lr: 0.200000\n","| Epoch: 50/120, val_loss: 0.756, val_acc: 83.180, lr: 0.200000\n","| Epoch [ 51/120] Iter[352/352]\t\tLoss: 2.0032 Acc@1: 40.509%, time: 1.180| Epoch: 51/120, val_loss: 1.887, val_acc: 52.940, lr: 0.200000\n","| Epoch: 51/120, val_loss: 0.757, val_acc: 83.100, lr: 0.200000\n","| Epoch [ 52/120] Iter[352/352]\t\tLoss: 1.9890 Acc@1: 40.673%, time: 1.173| Epoch: 52/120, val_loss: 1.019, val_acc: 55.800, lr: 0.200000\n","| Epoch: 52/120, val_loss: 0.711, val_acc: 83.460, lr: 0.200000\n","| Epoch [ 53/120] Iter[352/352]\t\tLoss: 1.9442 Acc@1: 40.567%, time: 1.183| Epoch: 53/120, val_loss: 1.795, val_acc: 46.160, lr: 0.200000\n","| Epoch: 53/120, val_loss: 0.693, val_acc: 83.600, lr: 0.200000\n","| Epoch [ 54/120] Iter[352/352]\t\tLoss: 1.9023 Acc@1: 40.896%, time: 1.172| Epoch: 54/120, val_loss: 1.717, val_acc: 54.160, lr: 0.200000\n","| Epoch: 54/120, val_loss: 0.680, val_acc: 83.640, lr: 0.200000\n","| Epoch [ 55/120] Iter[352/352]\t\tLoss: 2.0144 Acc@1: 41.116%, time: 1.182| Epoch: 55/120, val_loss: 1.455, val_acc: 58.900, lr: 0.200000\n","| Epoch: 55/120, val_loss: 0.634, val_acc: 83.860, lr: 0.200000\n","| Epoch [ 56/120] Iter[352/352]\t\tLoss: 1.9199 Acc@1: 41.218%, time: 1.175| Epoch: 56/120, val_loss: 1.109, val_acc: 57.220, lr: 0.200000\n","| Epoch: 56/120, val_loss: 0.661, val_acc: 84.020, lr: 0.200000\n","| Epoch [ 57/120] Iter[352/352]\t\tLoss: 1.8708 Acc@1: 41.342%, time: 1.173| Epoch: 57/120, val_loss: 1.211, val_acc: 55.700, lr: 0.200000\n","| Epoch: 57/120, val_loss: 0.650, val_acc: 84.260, lr: 0.200000\n","| Epoch [ 58/120] Iter[352/352]\t\tLoss: 2.0120 Acc@1: 41.449%, time: 1.174| Epoch: 58/120, val_loss: 1.590, val_acc: 55.600, lr: 0.200000\n","| Epoch: 58/120, val_loss: 0.646, val_acc: 84.380, lr: 0.200000\n","| Epoch [ 59/120] Iter[352/352]\t\tLoss: 1.8831 Acc@1: 41.602%, time: 1.177| Epoch: 59/120, val_loss: 1.608, val_acc: 60.240, lr: 0.200000\n","| Epoch: 59/120, val_loss: 0.690, val_acc: 84.300, lr: 0.200000\n","| Epoch [ 60/120] Iter[352/352]\t\tLoss: 1.8685 Acc@1: 41.391%, time: 1.177| Epoch: 60/120, val_loss: 1.722, val_acc: 54.520, lr: 0.200000\n","| Epoch: 60/120, val_loss: 0.722, val_acc: 84.320, lr: 0.200000\n","| Epoch [ 61/120] Iter[352/352]\t\tLoss: 1.9756 Acc@1: 41.682%, time: 1.181| Epoch: 61/120, val_loss: 2.001, val_acc: 47.460, lr: 0.200000\n","| Epoch: 61/120, val_loss: 0.691, val_acc: 84.580, lr: 0.200000\n","| Epoch [ 62/120] Iter[352/352]\t\tLoss: 1.8816 Acc@1: 41.649%, time: 1.173| Epoch: 62/120, val_loss: 0.980, val_acc: 63.960, lr: 0.200000\n","| Epoch: 62/120, val_loss: 0.688, val_acc: 84.580, lr: 0.200000\n","| Epoch [ 63/120] Iter[352/352]\t\tLoss: 1.9251 Acc@1: 41.769%, time: 1.176| Epoch: 63/120, val_loss: 1.147, val_acc: 56.780, lr: 0.200000\n","| Epoch: 63/120, val_loss: 0.666, val_acc: 84.580, lr: 0.200000\n","| Epoch [ 64/120] Iter[352/352]\t\tLoss: 1.9465 Acc@1: 42.093%, time: 1.172| Epoch: 64/120, val_loss: 1.063, val_acc: 60.740, lr: 0.200000\n","| Epoch: 64/120, val_loss: 0.675, val_acc: 84.820, lr: 0.200000\n","| Epoch [ 65/120] Iter[352/352]\t\tLoss: 1.7975 Acc@1: 42.162%, time: 1.172| Epoch: 65/120, val_loss: 0.949, val_acc: 63.400, lr: 0.200000\n","| Epoch: 65/120, val_loss: 0.676, val_acc: 85.080, lr: 0.200000\n","| Epoch [ 66/120] Iter[352/352]\t\tLoss: 1.9607 Acc@1: 42.489%, time: 1.172| Epoch: 66/120, val_loss: 0.783, val_acc: 64.320, lr: 0.200000\n","| Epoch: 66/120, val_loss: 0.677, val_acc: 85.220, lr: 0.200000\n","| Epoch [ 67/120] Iter[352/352]\t\tLoss: 1.7777 Acc@1: 42.344%, time: 1.172| Epoch: 67/120, val_loss: 1.213, val_acc: 63.100, lr: 0.200000\n","| Epoch: 67/120, val_loss: 0.710, val_acc: 85.120, lr: 0.200000\n","| Epoch [ 68/120] Iter[352/352]\t\tLoss: 2.1042 Acc@1: 42.249%, time: 1.171| Epoch: 68/120, val_loss: 0.976, val_acc: 62.760, lr: 0.200000\n","| Epoch: 68/120, val_loss: 0.688, val_acc: 85.040, lr: 0.200000\n","| Epoch [ 69/120] Iter[352/352]\t\tLoss: 1.8889 Acc@1: 42.720%, time: 1.177| Epoch: 69/120, val_loss: 1.093, val_acc: 56.160, lr: 0.200000\n","| Epoch: 69/120, val_loss: 0.656, val_acc: 85.260, lr: 0.200000\n","| Epoch [ 70/120] Iter[352/352]\t\tLoss: 1.8180 Acc@1: 42.562%, time: 1.182| Epoch: 70/120, val_loss: 1.077, val_acc: 58.160, lr: 0.200000\n","| Epoch: 70/120, val_loss: 0.659, val_acc: 85.440, lr: 0.200000\n","| Epoch [ 71/120] Iter[352/352]\t\tLoss: 2.0441 Acc@1: 42.651%, time: 1.174| Epoch: 71/120, val_loss: 1.174, val_acc: 65.820, lr: 0.200000\n","| Epoch: 71/120, val_loss: 0.655, val_acc: 85.580, lr: 0.200000\n","| Epoch [ 72/120] Iter[352/352]\t\tLoss: 1.7246 Acc@1: 42.956%, time: 1.172| Epoch: 72/120, val_loss: 1.205, val_acc: 63.500, lr: 0.200000\n","| Epoch: 72/120, val_loss: 0.631, val_acc: 85.280, lr: 0.200000\n","| Epoch [ 73/120] Iter[352/352]\t\tLoss: 1.7782 Acc@1: 42.953%, time: 1.172| Epoch: 73/120, val_loss: 0.984, val_acc: 63.380, lr: 0.200000\n","| Epoch: 73/120, val_loss: 0.640, val_acc: 85.240, lr: 0.200000\n","| Epoch [ 74/120] Iter[352/352]\t\tLoss: 1.9839 Acc@1: 43.098%, time: 1.178| Epoch: 74/120, val_loss: 0.719, val_acc: 58.820, lr: 0.200000\n","| Epoch: 74/120, val_loss: 0.642, val_acc: 85.280, lr: 0.200000\n","| Epoch [ 75/120] Iter[352/352]\t\tLoss: 1.6671 Acc@1: 42.962%, time: 1.172| Epoch: 75/120, val_loss: 1.221, val_acc: 61.840, lr: 0.200000\n","| Epoch: 75/120, val_loss: 0.596, val_acc: 85.340, lr: 0.200000\n","| Epoch [ 76/120] Iter[352/352]\t\tLoss: 1.9375 Acc@1: 43.111%, time: 1.173| Epoch: 76/120, val_loss: 1.652, val_acc: 62.760, lr: 0.200000\n","| Epoch: 76/120, val_loss: 0.608, val_acc: 85.400, lr: 0.200000\n","| Epoch [ 77/120] Iter[317/352]\t\tLoss: 1.7111 Acc@1: 43.151%, time: 1.858"],"name":"stdout"},{"output_type":"stream","text":["requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/xavierlopeze/Cifar_Experiment/1irk0t1w/file_stream. args: ('https://api.wandb.ai/files/xavierlopeze/Cifar_Experiment/1irk0t1w/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 158, 'content': ['2020-05-03T09:14:33.212327 | Epoch [ 77/120] Iter[296/352]\\t\\tLoss: 2.0602 Acc@1: 43.267%, time: 1.861\\r']}}}}\n"],"name":"stderr"},{"output_type":"stream","text":["| Epoch [ 77/120] Iter[319/352]\t\tLoss: 1.7075 Acc@1: 43.179%, time: 1.860"],"name":"stdout"},{"output_type":"stream","text":["requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/xavierlopeze/Cifar_Experiment/1irk0t1w/file_stream. args: ('https://api.wandb.ai/files/xavierlopeze/Cifar_Experiment/1irk0t1w/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 158, 'content': ['2020-05-03T09:14:33.212327 | Epoch [ 77/120] Iter[296/352]\\t\\tLoss: 2.0602 Acc@1: 43.267%, time: 1.861\\r']}}}}\n"],"name":"stderr"},{"output_type":"stream","text":["| Epoch [ 77/120] Iter[321/352]\t\tLoss: 1.8536 Acc@1: 43.193%, time: 1.859"],"name":"stdout"},{"output_type":"stream","text":["requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/xavierlopeze/Cifar_Experiment/1irk0t1w/file_stream. args: ('https://api.wandb.ai/files/xavierlopeze/Cifar_Experiment/1irk0t1w/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 158, 'content': ['2020-05-03T09:14:33.212327 | Epoch [ 77/120] Iter[296/352]\\t\\tLoss: 2.0602 Acc@1: 43.267%, time: 1.861\\r']}}}}\n"],"name":"stderr"},{"output_type":"stream","text":["| Epoch [ 77/120] Iter[352/352]\t\tLoss: 1.7552 Acc@1: 43.136%, time: 1.178| Epoch: 77/120, val_loss: 0.650, val_acc: 67.060, lr: 0.200000\n","| Epoch: 77/120, val_loss: 0.639, val_acc: 85.360, lr: 0.200000\n","| Epoch [ 78/120] Iter[352/352]\t\tLoss: 1.7120 Acc@1: 43.413%, time: 1.173| Epoch: 78/120, val_loss: 1.225, val_acc: 60.760, lr: 0.200000\n","| Epoch: 78/120, val_loss: 0.621, val_acc: 85.360, lr: 0.200000\n","| Epoch [ 79/120] Iter[352/352]\t\tLoss: 1.8603 Acc@1: 43.678%, time: 1.180| Epoch: 79/120, val_loss: 0.844, val_acc: 60.640, lr: 0.200000\n","| Epoch: 79/120, val_loss: 0.584, val_acc: 85.760, lr: 0.200000\n","| Epoch [ 80/120] Iter[352/352]\t\tLoss: 1.7259 Acc@1: 43.442%, time: 1.172| Epoch: 80/120, val_loss: 1.205, val_acc: 69.220, lr: 0.200000\n","| Epoch: 80/120, val_loss: 0.606, val_acc: 85.660, lr: 0.200000\n","| Epoch [ 81/120] Iter[352/352]\t\tLoss: 1.7486 Acc@1: 47.242%, time: 1.173| Epoch: 81/120, val_loss: 0.707, val_acc: 68.300, lr: 0.020000\n","| Epoch: 81/120, val_loss: 0.628, val_acc: 85.160, lr: 0.020000\n","| Epoch [ 82/120] Iter[352/352]\t\tLoss: 1.6419 Acc@1: 48.871%, time: 1.182| Epoch: 82/120, val_loss: 0.653, val_acc: 69.820, lr: 0.020000\n","| Epoch: 82/120, val_loss: 0.621, val_acc: 85.000, lr: 0.020000\n","| Epoch [ 83/120] Iter[352/352]\t\tLoss: 1.2185 Acc@1: 49.673%, time: 1.174| Epoch: 83/120, val_loss: 0.660, val_acc: 64.820, lr: 0.020000\n","| Epoch: 83/120, val_loss: 0.634, val_acc: 84.420, lr: 0.020000\n","| Epoch [ 84/120] Iter[352/352]\t\tLoss: 1.5220 Acc@1: 50.318%, time: 1.174| Epoch: 84/120, val_loss: 0.670, val_acc: 61.620, lr: 0.020000\n","| Epoch: 84/120, val_loss: 0.620, val_acc: 83.800, lr: 0.020000\n","| Epoch [ 85/120] Iter[352/352]\t\tLoss: 1.6072 Acc@1: 51.200%, time: 1.174| Epoch: 85/120, val_loss: 0.589, val_acc: 63.220, lr: 0.020000\n","| Epoch: 85/120, val_loss: 0.612, val_acc: 83.220, lr: 0.020000\n","| Epoch [ 86/120] Iter[352/352]\t\tLoss: 1.4003 Acc@1: 51.820%, time: 1.174| Epoch: 86/120, val_loss: 0.382, val_acc: 61.500, lr: 0.020000\n","| Epoch: 86/120, val_loss: 0.603, val_acc: 82.600, lr: 0.020000\n","| Epoch [ 87/120] Iter[352/352]\t\tLoss: 1.5349 Acc@1: 52.633%, time: 1.172| Epoch: 87/120, val_loss: 0.354, val_acc: 59.960, lr: 0.020000\n","| Epoch: 87/120, val_loss: 0.590, val_acc: 81.220, lr: 0.020000\n","| Epoch [ 88/120] Iter[352/352]\t\tLoss: 1.5196 Acc@1: 53.349%, time: 1.176| Epoch: 88/120, val_loss: 0.975, val_acc: 58.420, lr: 0.020000\n","| Epoch: 88/120, val_loss: 0.594, val_acc: 80.440, lr: 0.020000\n","| Epoch [ 89/120] Iter[352/352]\t\tLoss: 1.8493 Acc@1: 53.838%, time: 1.175| Epoch: 89/120, val_loss: 0.493, val_acc: 56.360, lr: 0.020000\n","| Epoch: 89/120, val_loss: 0.563, val_acc: 79.040, lr: 0.020000\n","| Epoch [ 90/120] Iter[352/352]\t\tLoss: 1.4010 Acc@1: 54.793%, time: 1.175| Epoch: 90/120, val_loss: 0.869, val_acc: 58.280, lr: 0.020000\n","| Epoch: 90/120, val_loss: 0.596, val_acc: 77.940, lr: 0.020000\n","| Epoch [ 91/120] Iter[352/352]\t\tLoss: 1.5134 Acc@1: 55.667%, time: 1.170| Epoch: 91/120, val_loss: 0.578, val_acc: 55.160, lr: 0.020000\n","| Epoch: 91/120, val_loss: 0.578, val_acc: 77.040, lr: 0.020000\n","| Epoch [ 92/120] Iter[352/352]\t\tLoss: 1.3343 Acc@1: 56.551%, time: 1.170| Epoch: 92/120, val_loss: 0.678, val_acc: 49.600, lr: 0.020000\n","| Epoch: 92/120, val_loss: 0.644, val_acc: 76.080, lr: 0.020000\n","| Epoch [ 93/120] Iter[352/352]\t\tLoss: 1.5309 Acc@1: 57.220%, time: 1.171| Epoch: 93/120, val_loss: 0.744, val_acc: 45.540, lr: 0.020000\n","| Epoch: 93/120, val_loss: 0.677, val_acc: 75.440, lr: 0.020000\n","| Epoch [ 94/120] Iter[352/352]\t\tLoss: 1.3896 Acc@1: 57.907%, time: 1.181| Epoch: 94/120, val_loss: 0.284, val_acc: 53.140, lr: 0.020000\n","| Epoch: 94/120, val_loss: 0.693, val_acc: 73.940, lr: 0.020000\n","| Epoch [ 95/120] Iter[352/352]\t\tLoss: 1.3875 Acc@1: 58.611%, time: 1.171| Epoch: 95/120, val_loss: 0.636, val_acc: 47.580, lr: 0.020000\n","| Epoch: 95/120, val_loss: 0.630, val_acc: 73.140, lr: 0.020000\n","| Epoch [ 96/120] Iter[352/352]\t\tLoss: 1.2927 Acc@1: 59.218%, time: 1.173| Epoch: 96/120, val_loss: 0.622, val_acc: 47.300, lr: 0.020000\n","| Epoch: 96/120, val_loss: 0.666, val_acc: 72.340, lr: 0.020000\n","| Epoch [ 97/120] Iter[352/352]\t\tLoss: 1.3747 Acc@1: 60.287%, time: 1.178| Epoch: 97/120, val_loss: 0.348, val_acc: 54.240, lr: 0.020000\n","| Epoch: 97/120, val_loss: 0.610, val_acc: 71.760, lr: 0.020000\n","| Epoch [ 98/120] Iter[352/352]\t\tLoss: 1.1516 Acc@1: 61.282%, time: 1.174| Epoch: 98/120, val_loss: 0.477, val_acc: 48.180, lr: 0.020000\n","| Epoch: 98/120, val_loss: 0.642, val_acc: 71.500, lr: 0.020000\n","| Epoch [ 99/120] Iter[352/352]\t\tLoss: 1.2508 Acc@1: 61.909%, time: 1.179| Epoch: 99/120, val_loss: 0.815, val_acc: 44.680, lr: 0.020000\n","| Epoch: 99/120, val_loss: 0.670, val_acc: 70.260, lr: 0.020000\n","| Epoch [100/120] Iter[352/352]\t\tLoss: 1.0407 Acc@1: 62.900%, time: 1.176| Epoch: 100/120, val_loss: 0.340, val_acc: 45.080, lr: 0.020000\n","| Epoch: 100/120, val_loss: 0.665, val_acc: 69.340, lr: 0.020000\n","| Epoch [101/120] Iter[352/352]\t\tLoss: 1.3676 Acc@1: 64.084%, time: 1.174| Epoch: 101/120, val_loss: 0.487, val_acc: 41.680, lr: 0.020000\n","| Epoch: 101/120, val_loss: 0.791, val_acc: 67.840, lr: 0.020000\n","| Epoch [102/120] Iter[352/352]\t\tLoss: 0.9038 Acc@1: 64.842%, time: 1.173| Epoch: 102/120, val_loss: 0.474, val_acc: 43.300, lr: 0.020000\n","| Epoch: 102/120, val_loss: 0.746, val_acc: 67.120, lr: 0.020000\n","| Epoch [103/120] Iter[352/352]\t\tLoss: 1.2114 Acc@1: 65.953%, time: 1.175| Epoch: 103/120, val_loss: 0.935, val_acc: 46.320, lr: 0.020000\n","| Epoch: 103/120, val_loss: 0.754, val_acc: 66.220, lr: 0.020000\n","| Epoch [104/120] Iter[352/352]\t\tLoss: 1.2890 Acc@1: 66.760%, time: 1.176| Epoch: 104/120, val_loss: 0.558, val_acc: 42.400, lr: 0.020000\n","| Epoch: 104/120, val_loss: 0.758, val_acc: 65.280, lr: 0.020000\n","| Epoch [105/120] Iter[179/352]\t\tLoss: 0.9850 Acc@1: 69.667%, time: 1.859"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oyyFzY5r6yTV","colab_type":"text"},"source":[""]}]}