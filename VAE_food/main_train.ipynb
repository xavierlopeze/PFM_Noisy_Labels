{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"main_train.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f12f72a31d2848908fd5c0b1115b7c5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6a49fc46b8d04fd1875c3cfa9aca301d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_be6afe0808a14d66911517ba15926394","IPY_MODEL_3ef324cc1e2b47bf906d1bf9dd15c06d"]}},"6a49fc46b8d04fd1875c3cfa9aca301d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"be6afe0808a14d66911517ba15926394":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6c3e9fc444c64b17ac17cdfd1b054929","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":102502400,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102502400,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_55846720fca64c0cb9c79b2b451dc458"}},"3ef324cc1e2b47bf906d1bf9dd15c06d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d9a31f321fcc46129db880628e3909da","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [00:00&lt;00:00, 221MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a618e920bb34987a4f78e8aeafb3d3b"}},"6c3e9fc444c64b17ac17cdfd1b054929":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"55846720fca64c0cb9c79b2b451dc458":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9a31f321fcc46129db880628e3909da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a618e920bb34987a4f78e8aeafb3d3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"6yLSwlM9I5XX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597249449347,"user_tz":-120,"elapsed":1459,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FaU-pKwkI6tH","colab_type":"text"},"source":["## 1. Google Colab Settings:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2AiEquVKc481","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597249740232,"user_tz":-120,"elapsed":13440,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"02bec778-aa58-425e-d478-ee11ed5c709d"},"source":["!pip install wandb"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/19/f8db9eff4b0173adf6dd2e8b0c3d8de0bfe10ec9ed63d247665980d82258/wandb-0.9.4-py2.py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/1e/a45320cab182bf1c8656107b3d4c042e659742822fc6bff150d769a984dd/GitPython-3.1.7-py3-none-any.whl (158kB)\n","\u001b[K     |████████████████████████████████| 163kB 19.0MB/s \n","\u001b[?25hCollecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 8.1MB/s \n","\u001b[?25hCollecting gql==0.2.0\n","  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.15.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.13)\n","Collecting watchdog>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n","\u001b[K     |████████████████████████████████| 102kB 9.1MB/s \n","\u001b[?25hCollecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/23/811fcdfc9d67fea7e47c91dd553081218d53dda744c28384f4d2f69206c9/sentry_sdk-0.16.3-py2.py3-none-any.whl (110kB)\n","\u001b[K     |████████████████████████████████| 112kB 18.7MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n","\u001b[?25hCollecting graphql-core<2,>=0.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb) (2.3)\n","Collecting pathtools>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.6.20)\n","Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.10)\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n","Building wheels for collected packages: subprocess32, gql, watchdog, graphql-core, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=8a6ea687f09c7e8790acf23b2ee72f3dc8ee3e5ecc029b3c49aa47dee8875bfe\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=aeb635f7fb6cb21b3ff17274fc21f503534a0d5970055c4f8a5e5f35dc0eca0e\n","  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73870 sha256=47cc5d0303bf2a99d98c5b4b0104382f569f19b66455528124abcbf2f69b94ef\n","  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n","  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=54f39ee955bd845d70b4bc15103efb3dc323bcdc28cb02a59a7afa68b253de44\n","  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=b2d6d07531b8c722adfb6ff8cd7ffb1e42dfaabfbf830f08ca625139c47d1b37\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built subprocess32 gql watchdog graphql-core pathtools\n","Installing collected packages: smmap, gitdb, GitPython, subprocess32, graphql-core, gql, docker-pycreds, pathtools, watchdog, sentry-sdk, configparser, shortuuid, wandb\n","Successfully installed GitPython-3.1.7 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 pathtools-0.1.2 sentry-sdk-0.16.3 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 wandb-0.9.4 watchdog-0.10.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"88ezc8iRdkqg","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1597249851237,"user_tz":-120,"elapsed":124390,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"d9b3da9f-8c95-4f8a-d08a-6b21f9c0b0b1"},"source":["!wandb login"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: dff003aa03e7d25df35a840b6f0660ae9675efb4\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FtR2kR_rtLk3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597249851239,"user_tz":-120,"elapsed":124351,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8skRpihGdp1q","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"ok","timestamp":1597249852661,"user_tz":-120,"elapsed":125744,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"f6c8e77e-d2cf-45ae-a8f6-c26f3e469e05"},"source":["#GPU INFO\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Wed Aug 12 16:30:51 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"csakjx4mdrs5","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1597249869263,"user_tz":-120,"elapsed":142295,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"2c5d000a-fd6e-475b-cbf6-79cd8d138a2f"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zoV2tev1jHbQ","colab":{},"executionInfo":{"status":"ok","timestamp":1597249869264,"user_tz":-120,"elapsed":142257,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/VAE_food')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MQ2EmBmaNMG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597249869264,"user_tz":-120,"elapsed":142233,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":[""],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IBoUN-QKJUGJ","colab_type":"text"},"source":["## 2. Import packages and initalize model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Xq88YZuGhRTA","colab":{"base_uri":"https://localhost:8080/","height":117},"executionInfo":{"status":"ok","timestamp":1597249891066,"user_tz":-120,"elapsed":164013,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"232c7277-c5f2-4b52-95b7-e930c30296ea"},"source":["# Pytorch libraries\n","import torch\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","# Internal files\n","import config\n","import dataloader\n","import models\n","\n","# from baseline import get_model, save_checkpoint\n","\n","import math\n","import pandas\n","import os\n","import sys\n","import time\n","from collections import OrderedDict\n","import random\n","\n","import wandb\n","import pandas"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\n","noise file noisy_label_kv30_sim.txt generated with noise: 0.3\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://app.wandb.ai/xavierlopeze/Food101_Noise_Server\" target=\"_blank\">https://app.wandb.ai/xavierlopeze/Food101_Noise_Server</a><br/>\n","                Run page: <a href=\"https://app.wandb.ai/xavierlopeze/Food101_Noise_Server/runs/26la8d0j\" target=\"_blank\">https://app.wandb.ai/xavierlopeze/Food101_Noise_Server/runs/26la8d0j</a><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"z1l_EzNNaPLx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597249891067,"user_tz":-120,"elapsed":163972,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"f38b07b6-76de-4742-ad7c-9725bdee0bde"},"source":["config.checkpoint"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'vae_weights/vae_weights'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tsMIDod2mpPz","colab":{},"executionInfo":{"status":"ok","timestamp":1597249891068,"user_tz":-120,"elapsed":163943,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["def get_model():\n","\n","    # Get model from config\n","    if config.model == \"resnet18\":\n","        model = models.resnet18(pretrained=config.pretrained)\n","    elif config.model == \"resnet34\":\n","        model = models.resnet34(pretrained=config.pretrained)\n","    elif config.model == 'resnet50':\n","        model = models.resnet50_fc(pretrained=config.pretrained)\n","    elif config.model == \"resnet101\":\n","        model = models.resnet101(pretrained=config.pretrained)\n","    elif config.model == \"resnet152\":\n","        model = models.resnet152(pretrained=config.pretrained)\n","    elif config.model == \"resnext50_32x4d\":\n","        model = models.resnet34(pretrained=config.pretrained)\n","    elif config.model == 'resnext101_32x8d':\n","        model = models.resnet50(pretrained=config.pretrained)\n","    elif config.model == \"wide_resnet50_2\":\n","        model = models.resnet101(pretrained=config.pretrained)\n","    elif config.model == \"wide_resnet101_2\":\n","        model = models.resnet152(pretrained=config.pretrained)\n","    else:\n","        raise ValueError('%s not supported'.format(config.model))\n","\n","    # Initialize fc layer\n","    (in_features, out_features) = model.fc.in_features, model.fc.out_features\n","    model.fc = torch.nn.Linear(in_features, out_features)\n","    return model\n","\n","\n","\n","def save_checkpoint(state, filename='checkpoint.pth.tar'):\n","    torch.save(state, filename)\n","    if config.use_wandb == True:\n","        wandb.save(filename)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"87YtwkMEWPOG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597249891069,"user_tz":-120,"elapsed":163907,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"cf715641-4919-4997-f5fe-0595bec51dcf"},"source":["config.checkpoint"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'vae_weights/vae_weights'"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"nSoOGHhMBIeo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597249891358,"user_tz":-120,"elapsed":164166,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["def scheduler(epoch: int):\n","    global lr\n","    lr = config.lr\n","    if epoch > config.start_epoch:\n","        lr = lr / 10.0\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","# Training\n","def train(epoch):\n","    global init\n","    net.train()\n","    tch_net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    scheduler(epoch)\n","\n","\n","    # ramp up meta-learning rate and EMA decay\n","    if epoch <= config.param_epoch:\n","        u = epoch/config.param_epoch\n","        meta_lr = config.meta_lr*math.exp(-5*(1-u)**2)\n","        lamb = 0.5*math.exp(-5*(1-u)**2)\n","    else:\n","        meta_lr = config.meta_lr\n","        config.eps = 0.999\n","\n","    for step, (inputs, targets) in enumerate(train_loader):\n","        init_time = time.time()\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","\n","        class_loss = criterion(outputs, targets)\n","        class_loss.backward(retain_graph=True)\n","\n","\n","        if step > config.start_iter or epoch > 1:\n","        #if step > 0 or epoch > 0:\n","\n","            # if step > config.mid_iter or epoch > 1:\n","            #     # config.eps = 0.999\n","            #     alpha = config.alpha\n","            # else:\n","            #     u = (step - config.start_iter)/(config.mid_iter - config.start_iter)\n","            #     alpha = config.alpha*math.exp(-5*(1-u)**2)\n","            alpha = config.alpha\n","\n","            if init:\n","                init = False\n","                for param, param_tch in zip(net.parameters(), tch_net.parameters()):\n","                    param_tch.data.copy_(param.data)\n","            else:\n","                for param, param_tch in zip(net.parameters(), tch_net.parameters()):\n","                    param_tch.data.mul_(config.eps).add_((1-config.eps), param.data)\n","\n","            _, feats = pretrain_net(inputs, get_feat=True)\n","            tch_outputs = tch_net(inputs, get_feat=False)\n","            p_tch = F.softmax(tch_outputs, dim=1)\n","            p_tch.detach_()\n","\n","            if use_mentor == True:\n","                mnt_outputs = mentor_net(inputs, get_feat=False)\n","                p_mnt = F.softmax(tch_outputs, dim=1)\n","                p_mnt.detach_()\n","\n","            for i in range(config.num_fast):\n","                targets_fast = targets.clone()\n","                randidx = torch.randperm(targets.size(0))\n","                for n in range(int(targets.size(0)*config.perturb_ratio)):\n","                    num_neighbor = 1\n","                    idx = randidx[n]\n","                    feat = feats[idx]\n","                    feat.view(1, feat.size(0))\n","                    feat.data = feat.data.expand(targets.size(0), feat.size(0))\n","                    dist = torch.sum((feat-feats)**2, dim=1)\n","                    _, neighbor = torch.topk(dist.data, num_neighbor+1, largest=False)\n","                    targets_fast[idx] = targets[neighbor[random.randint(1, num_neighbor)]]\n","                    \n","\n","\n","                fast_loss = criterion(outputs, targets_fast)\n","\n","                grads = torch.autograd.grad(fast_loss, net.parameters(),\n","                                            create_graph=False,\n","                                            retain_graph=True,\n","                                            only_inputs=True)\n","\n","                fast_weights = OrderedDict(\n","                    (name, param - meta_lr*grad)\n","                    for ((name, param), grad) in zip(net.named_parameters(), grads))\n","\n","                fast_out = net.forward(inputs,fast_weights)\n","\n","                logp_fast = F.log_softmax(fast_out,dim=1)\n","\n","                #afegir canvis per iterative aquí\n","                if use_mentor == False:\n","                    consistent_loss = consistent_criterion(logp_fast, p_tch)\n","                else:\n","                    consistent_loss = consistent_criterion(logp_fast, p_tch*lamb + p_mnt*(1-lamb))\n","\n","                consistent_loss = consistent_loss*alpha/config.num_fast\n","                consistent_loss.backward()\n","\n","        optimizer.step()\n","\n","        # train_loss += class_loss.data.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","\n","        # Grab training results\n","        sys.stdout.write('\\r')\n","        sys.stdout.write('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%, time: %.3f'\n","              %(epoch, config.num_epochs, step+1, (len(train_loader.dataset)//config.batch_size)+1, class_loss.data.item(), 100.*correct/total,time.time() - init_time))\n","        sys.stdout.flush()\n","\n","\n","\n","def valid(epoch, network):\n","    global best_acc\n","    network.eval()\n","    # val_loss = 0\n","    correct = 0\n","    total = 0\n","    for step, (inputs, targets) in enumerate(valid_loader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        with torch.no_grad():\n","            outputs = network(inputs)\n","            loss = criterion(outputs, targets)\n","\n","        # valid_loss += loss.data.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","\n","        # Grab validation results\n","        valid_acc = 100. * correct / total\n","      # valid_results = (\"| Epoch: {}/{}, val_loss: {:.3f}, val_acc: {:.3f}, \"\n","      #                 \"lr: {:.6f}\".format(epoch,\n","      #                                     config.num_epochs,\n","      #                                     loss.data.item(),\n","      #                                     valid_acc,\n","      #                                     lr))\n","        # Grab validation results\n","        valid_results = (\"| Epoch: {}/{}, val_loss: {:.3f}, val_acc: {:.3f}, \"\"lr: {:.6f}\".format(epoch,config.num_epochs,loss.data.item(),valid_acc,lr))\n","        record.write(valid_results + '\\n')\n","        record.flush()\n","\n","\n","\n","    # Save checkpoint when best model\n","    if valid_acc > best_acc:\n","        best_acc = valid_acc\n","        print('| Saving Best Model ...', end=\"\\r\")\n","        save_point = config.drive_dir + '/checkpoint/' + config.id + '.pth.tar'\n","        save_checkpoint({\n","            'state_dict': network.state_dict(),\n","            'best_acc': best_acc,\n","        }, save_point)\n","\n","    wandb.log({'epoch': epoch, 'accy_val' : best_acc })\n","\n","    return valid_results\n","\n","\n","def test():\n","    test_net.eval()\n","    # test_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(valid_loader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        with torch.no_grad():\n","            outputs = test_net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","        # test_loss += loss.data.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","\n","    # Grab validation results\n","    test_acc = 100. * correct/total\n","    test_results = \"| test_loss: {:.3f}, test_acc: {:.3f}\".format(\n","        loss.data.item(), test_acc)\n","    record.write(test_results)\n","    record.flush()\n","\n","    print(test_results)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"emKraA_eBNxQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597249891359,"user_tz":-120,"elapsed":164140,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["def save_weights(epoch):\n","        print('| Saving Weights student ...', end=\"\\r\")\n","        save_point = config.drive_dir + '/checkpoint/' + config.id + '_student_' + str(epoch) + '.pth.tar'\n","        save_checkpoint({'state_dict': net.state_dict(), }, save_point)\n","\n","        print('| Saving Weights teacher ...', end=\"\\r\")\n","        save_point = config.drive_dir + '/checkpoint/' + config.id + '_teacher_' + str(epoch) + '.pth.tar'\n","        save_checkpoint({'state_dict': tch_net.state_dict(), }, save_point)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9mjWKzpX9L_W","colab":{"base_uri":"https://localhost:8080/","height":334,"referenced_widgets":["f12f72a31d2848908fd5c0b1115b7c5f","6a49fc46b8d04fd1875c3cfa9aca301d","be6afe0808a14d66911517ba15926394","3ef324cc1e2b47bf906d1bf9dd15c06d","6c3e9fc444c64b17ac17cdfd1b054929","55846720fca64c0cb9c79b2b451dc458","d9a31f321fcc46129db880628e3909da","4a618e920bb34987a4f78e8aeafb3d3b"]},"executionInfo":{"status":"ok","timestamp":1597249911116,"user_tz":-120,"elapsed":183872,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"9f0ca72e-1a78-44e5-fb9b-aaddb3fd7772"},"source":["# Checkpoint dir.\n","# record = open(config.drive_dir + '/checkpoint/' + config.checkpoint + '_test.txt', 'w')\n","#ecord.write('noise_rate=%s\\n' % config.noise_rate)\n","# record.flush()\n","\n","# Get the original_dataset\n","loader = dataloader.KeyDataLoader()\n","train_loader, valid_loader, test_loader = loader.run()\n","\n","# Hyper Parameter settings\n","random.seed(config.seed)\n","# torch.cuda.set_device(config.gpuid)\n","torch.manual_seed(config.seed)\n","torch.cuda.manual_seed_all(config.seed)\n","use_cuda = torch.cuda.is_available()\n","\n","# Networks setup\n","print('\\nModel setup')\n","print('| Building network: {}'.format(config.model))\n","net = get_model()\n","tch_net = get_model()\n","# pretrain_net = get_model()\n","test_net = get_model()\n","\n","#get pretrained net from vae checkpoint\n","latent_size = 500\n","\n","encoder = models.resnet34()\n","# encoder.eval()\n","decoder = models.decoder31()\n","# decoder.eval()\n","pretrain_net = models.VAE(encoder, decoder, latent_size)\n","# vae.eval()\n","\n","checkpoint = torch.load('/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/VAE_food/checkpoint/vae_weights.pth.tar', map_location='cpu')\n","pretrain_net.load_state_dict(checkpoint['state_dict'])\n","\n","\n","\n","print('| load pretrained net. from checkpoint...')\n","checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.checkpoint + '.pth.tar')\n","pretrain_net.load_state_dict(checkpoint['state_dict'])\n","\n","if use_cuda:\n","    net.cuda()\n","    tch_net.cuda()\n","    pretrain_net.cuda()\n","    test_net.cuda()\n","    cudnn.benchmark = True\n","pretrain_net.eval()\n","\n","for param in tch_net.parameters():\n","    param.requires_grad = False\n","for param in pretrain_net.parameters():\n","    param.requires_grad = False\n","\n","# Instantiate a loss function.\n","criterion = torch.nn.CrossEntropyLoss()\n","consistent_criterion = torch.nn.KLDivLoss()\n","\n","# Instantiate an optimizer to train the model\n","optimizer = torch.optim.SGD(\n","    net.parameters(), lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n","\n","print('\\nTraining model')\n","print('| Training Epochs = ' + str(config.num_epochs))\n","print('| Initial Learning Rate = ' + str(config.lr))\n","print('| Optimizer = ' + str(config.optimizer_type))\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","Model setup\n","| Building network: resnet50\n"],"name":"stdout"},{"output_type":"stream","text":["/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/VAE_food/models/resnet_fc.py:115: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(m.weight, mode='fan_out')\n","/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/VAE_food/models/resnet_fc.py:117: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(m.weight, 1)\n","/content/drive/My Drive/Colab_Notebooks/git/PFM_Noisy_Labels/VAE_food/models/resnet_fc.py:118: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  nn.init.constant(m.bias, 0)\n","Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f12f72a31d2848908fd5c0b1115b7c5f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","| load pretrained net. from checkpoint...\n","\n","Training model\n","| Training Epochs = 5\n","| Initial Learning Rate = 0.008\n","| Optimizer = SGD\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eMKeArg7viWN","colab":{},"executionInfo":{"status":"ok","timestamp":1597249911117,"user_tz":-120,"elapsed":183822,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["def get_accy(loader):\n","    test_net.eval()\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets, path) in enumerate(loader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        with torch.no_grad():\n","            outputs = test_net(inputs)\n","            loss = criterion(outputs, targets)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cuda().sum()\n","\n","    # Grab results results\n","    test_acc = 100. * correct/total\n","    test_results = \"| loss: {:.3f}, acc: {:.3f}\".format(\n","        loss.data.item(), test_acc)\n","\n","    print(test_results)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"B433Yzj-EI8D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":388},"executionInfo":{"status":"error","timestamp":1597255790211,"user_tz":-120,"elapsed":6062810,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}},"outputId":"a287b4b9-bab2-40a7-d933-640c562c6185"},"source":["\n","#set mentor parameter on the train funciton\n","use_mentor = False\n","init = True\n","best_acc = 0\n","for epoch in range(1, 1 + config.num_epochs):\n","    train(epoch)\n","    # Student validation\n","    std_results = valid(epoch, net)\n","    record.write(std_results + '\\n')\n","    print(std_results)\n","    # Teacher validation\n","    tch_results = valid(epoch, tch_net)\n","    record.write(tch_results + '\\n')\n","    record.flush()\n","    print(tch_results)\n","\n","    save_weights(epoch)\n","\n","print('\\nTesting model')\n","checkpoint = torch.load(config.drive_dir + '/checkpoint/%s.pth.tar' % config.id)\n","test_net.load_state_dict(checkpoint['state_dict'])\n","test()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["| Epoch [  1/  5] Iter[501/1066]\t\tLoss: 4.1903 Acc@1: 17.983%, time: 0.170"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-bef8fcc75ca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Student validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstd_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-024446914220>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0mparam_tch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mtch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtch_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_feat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mp_tch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'get_feat'"]}]},{"cell_type":"code","metadata":{"id":"xcU-eBzDViIR","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597255789922,"user_tz":-120,"elapsed":6061742,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["get_accy(test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eI9qxE4yViCi","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597255789925,"user_tz":-120,"elapsed":6061201,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["config.r"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nE9iK3OSY7j","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597255789926,"user_tz":-120,"elapsed":6060569,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.id + '.pth.tar')\n","test_net.load_state_dict(checkpoint['state_dict'])\n","\n","get_accy(train_loader)\n","get_accy(valid_loader)\n","get_accy(test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6hUmR1rgoR_","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597255789927,"user_tz":-120,"elapsed":6060016,"user":{"displayName":"Xavier López","photoUrl":"","userId":"17793741074420892205"}}},"source":["checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.checkpoint + '.pth.tar')\n","test_net.load_state_dict(checkpoint['state_dict'])\n","\n","get_accy(train_loader)\n","get_accy(valid_loader)\n","get_accy(test_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWvN30dGVvOV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"47a8b14c-bf5f-4f03-dd59-3d224be704f8"},"source":["EPOCH = 2 #Input the last epoch computed\n","\n","print('Load Student')\n","checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.id + '_student_' + str(EPOCH) + '.pth.tar' )\n","net.load_state_dict(checkpoint['state_dict'])\n","\n","print('Load Teacher')\n","checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.id + '_teacher_' + str(EPOCH) + '.pth.tar' )\n","tch_net.load_state_dict(checkpoint['state_dict'])\n","\n","# print('Load Mentor')\n","# checkpoint = torch.load(config.drive_dir + '/checkpoint/MLNT.pth.tar')\n","# mentor_net.load_state_dict(checkpoint['state_dict'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load Student\n","Load Teacher\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"b0YgEj5bVvGw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":258},"outputId":"a5ced5e6-c33a-4f6c-d20d-0224e13f11f0"},"source":["init = False\n","best_acc = 0\n","use_mentor = False\n","for epoch in range(EPOCH+1, 5):\n","    train(epoch)\n","    # Student validation\n","    std_results = valid(epoch, net)\n","    record.write(std_results + '\\n')\n","    print(std_results)\n","    # Teacher validation\n","    tch_results = valid(epoch, tch_net)\n","    record.write(tch_results + '\\n')\n","    record.flush()\n","    print(tch_results)\n","\n","    save_weights(epoch)\n","\n","print('\\nTesting model')\n","checkpoint = torch.load(config.drive_dir + '/checkpoint/%s.pth.tar' % config.id)\n","test_net.load_state_dict(checkpoint['state_dict'])\n","test()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2247: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n","  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"],"name":"stderr"},{"output_type":"stream","text":["| Epoch: 3/5, val_loss: 0.507, val_acc: 64.568, lr: 0.000800\n","| Epoch: 3/5, val_loss: 0.408, val_acc: 68.766, lr: 0.000800\n","| Epoch [  4/  5] Iter[1066/1066]\t\tLoss: 2.5688 Acc@1: 45.699%, time: 1.556| Epoch: 4/5, val_loss: 0.299, val_acc: 65.281, lr: 0.000800\n","| Epoch: 4/5, val_loss: 0.325, val_acc: 68.594, lr: 0.000800\n","\n","Testing model\n","| test_loss: 0.408, test_acc: 68.766\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HeHDif-kVvAr","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wGGw2snQQkmi","colab_type":"code","colab":{}},"source":["print('\\nTesting model')\n","checkpoint = torch.load(config.drive_dir + '/checkpoint/' + config.id + '.pth.tar')\n","mentor_net.load_state_dict(checkpoint['state_dict'])\n","print('\\n Validation Accy:')\n","get_accy(valid_loader)\n","print('\\n Test Accy:')\n","get_accy(test_loader)\n","print('\\n Train Accy:')\n","get_accy(train_loader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1kb_iR0Qp5n","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-50knnH5Nj_x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"fbc99f34-3337-4403-ba5e-960296e474d4"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"F2Chm4SbNmwy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Xe4vDEYSV_d","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}